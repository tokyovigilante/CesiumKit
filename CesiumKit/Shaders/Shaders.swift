//
//  Shaders.swift
//  CesiumKit
//
//  Autogenerated by ShaderParser.
//  Copyright (c) 2014 Test Toast. All rights reserved.
//

let Shaders: [String: String] = [
    "AdjustTranslucentFS": "\n#ifdef MRT\n#extension GL_EXT_draw_buffers : enable\n#endif\n\nuniform vec4 u_bgColor;\nuniform sampler2D u_depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    if (texture2D(u_depthTexture, v_textureCoordinates).r < 1.0)\n    {\n#ifdef MRT\n        gl_FragData[0] = u_bgColor;\n        gl_FragData[1] = vec4(u_bgColor.a);\n#else\n        gl_FragColor = u_bgColor;\n#endif\n        return;\n    }\n    \n    discard;\n}",

    "BillboardCollectionFS": "\nuniform sampler2D u_atlas;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef RENDER_FOR_PICK\nvarying vec4 v_pickColor;\n#else\nvarying vec4 v_color;\n#endif\n\nvoid main()\n{\n#ifdef RENDER_FOR_PICK\n    vec4 vertexColor = vec4(1.0, 1.0, 1.0, 1.0);\n#else\n    vec4 vertexColor = v_color;\n#endif\n    \n    vec4 color = texture2D(u_atlas, v_textureCoordinates) * vertexColor;\n    if (color.a == 0.0)\n    {\n        discard;\n    }\n    \n#ifdef RENDER_FOR_PICK\n    gl_FragColor = v_pickColor;\n#else\n    gl_FragColor = color;\n#endif\n}",

    "BillboardCollectionVS": "#ifdef INSTANCED\nattribute vec2 direction;\n#endif\nattribute vec4 positionHighAndScale;\nattribute vec4 positionLowAndRotation;   \nattribute vec4 compressedAttribute0;        // pixel offset, translate, horizontal origin, vertical origin, show, direction, texture coordinates (texture offset)\nattribute vec4 compressedAttribute1;        // aligned axis, translucency by distance, image width\nattribute vec4 compressedAttribute2;        // image height, color, pick color, size in meters, valid aligned axis, 13 bits free\nattribute vec4 eyeOffset;                   // eye offset in meters, 4 bytes free (texture range)\nattribute vec4 scaleByDistance;             // near, nearScale, far, farScale\nattribute vec4 pixelOffsetScaleByDistance;  // near, nearScale, far, farScale\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef RENDER_FOR_PICK\nvarying vec4 v_pickColor;\n#else\nvarying vec4 v_color;\n#endif\n\nconst float UPPER_BOUND = 32768.0;\n\nconst float SHIFT_LEFT16 = 65536.0;\nconst float SHIFT_LEFT8 = 256.0;\nconst float SHIFT_LEFT7 = 128.0;\nconst float SHIFT_LEFT5 = 32.0;\nconst float SHIFT_LEFT3 = 8.0;\nconst float SHIFT_LEFT2 = 4.0;\nconst float SHIFT_LEFT1 = 2.0;\n\nconst float SHIFT_RIGHT8 = 1.0 / 256.0;\nconst float SHIFT_RIGHT7 = 1.0 / 128.0;\nconst float SHIFT_RIGHT5 = 1.0 / 32.0;\nconst float SHIFT_RIGHT3 = 1.0 / 8.0;\nconst float SHIFT_RIGHT2 = 1.0 / 4.0;\nconst float SHIFT_RIGHT1 = 1.0 / 2.0;\n\nvec4 computePositionWindowCoordinates(vec4 positionEC, vec2 imageSize, float scale, vec2 direction, vec2 origin, vec2 translate, vec2 pixelOffset, vec3 alignedAxis, bool validAlignedAxis, float rotation, bool sizeInMeters)\n{\n    vec2 halfSize = imageSize * scale * czm_resolutionScale;\n    halfSize *= ((direction * 2.0) - 1.0);\n    \n    if (sizeInMeters)\n    {\n        positionEC.xy += halfSize;\n    }\n    \n    vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n    \n    if (sizeInMeters)\n    {\n        positionWC.xy += (origin * abs(halfSize)) / czm_metersPerPixel(positionEC);\n    }\n    else\n    {\n        positionWC.xy += (origin * abs(halfSize));\n    }\n    \n#if defined(ROTATION) || defined(ALIGNED_AXIS)\n    if (validAlignedAxis || rotation != 0.0)\n    {\n        float angle = rotation;\n        if (validAlignedAxis)\n        {\n            vec3 pos = positionEC.xyz + czm_encodedCameraPositionMCHigh + czm_encodedCameraPositionMCLow;\n            vec3 normal = normalize(cross(alignedAxis, pos));\n            vec4 tangent = vec4(normalize(cross(pos, normal)), 0.0);\n            tangent = czm_modelViewProjection * tangent;\n            angle += sign(-tangent.x) * acos(tangent.y / length(tangent.xy));\n        }\n        \n        float cosTheta = cos(angle);\n        float sinTheta = sin(angle);\n        mat2 rotationMatrix = mat2(cosTheta, sinTheta, -sinTheta, cosTheta);\n        halfSize = rotationMatrix * halfSize;\n    }\n#endif\n    \n    if (!sizeInMeters)\n    {\n        positionWC.xy += halfSize;\n    }\n    \n    positionWC.xy += translate;\n    positionWC.xy += (pixelOffset * czm_resolutionScale);\n    \n    return positionWC;\n}\n\nvoid main() \n{\n    // Modifying this shader may also require modifications to Billboard._computeScreenSpacePosition\n    \n    // unpack attributes\n    vec3 positionHigh = positionHighAndScale.xyz;\n    vec3 positionLow = positionLowAndRotation.xyz;\n    float scale = positionHighAndScale.w;\n    \n#if defined(ROTATION) || defined(ALIGNED_AXIS)\n    float rotation = positionLowAndRotation.w;\n#else\n    float rotation = 0.0;\n#endif\n\n    float compressed = compressedAttribute0.x;\n    \n    vec2 pixelOffset;\n    pixelOffset.x = floor(compressed * SHIFT_RIGHT7);\n    compressed -= pixelOffset.x * SHIFT_LEFT7;\n    pixelOffset.x -= UPPER_BOUND;\n    \n    vec2 origin;\n    origin.x = floor(compressed * SHIFT_RIGHT5);\n    compressed -= origin.x * SHIFT_LEFT5;\n    \n    origin.y = floor(compressed * SHIFT_RIGHT3);\n    compressed -= origin.y * SHIFT_LEFT3;\n    \n    origin -= vec2(1.0);\n    \n    float show = floor(compressed * SHIFT_RIGHT2);\n    compressed -= show * SHIFT_LEFT2;\n\n#ifdef INSTANCED\n    vec2 textureCoordinatesBottomLeft = czm_decompressTextureCoordinates(compressedAttribute0.w);\n    vec2 textureCoordinatesRange = czm_decompressTextureCoordinates(eyeOffset.w);\n    vec2 textureCoordinates = textureCoordinatesBottomLeft + direction * textureCoordinatesRange;\n#else\n    vec2 direction;\n    direction.x = floor(compressed * SHIFT_RIGHT1);\n    direction.y = compressed - direction.x * SHIFT_LEFT1;\n\n    vec2 textureCoordinates = czm_decompressTextureCoordinates(compressedAttribute0.w);\n#endif\n    \n    float temp = compressedAttribute0.y  * SHIFT_RIGHT8;\n    pixelOffset.y = -(floor(temp) - UPPER_BOUND);\n    \n    vec2 translate;\n    translate.y = (temp - floor(temp)) * SHIFT_LEFT16;\n    \n    temp = compressedAttribute0.z * SHIFT_RIGHT8;\n    translate.x = floor(temp) - UPPER_BOUND;\n    \n    translate.y += (temp - floor(temp)) * SHIFT_LEFT8;\n    translate.y -= UPPER_BOUND;\n\n    temp = compressedAttribute1.x * SHIFT_RIGHT8;\n    \n    vec2 imageSize = vec2(floor(temp), compressedAttribute2.w);\n    \n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    vec4 translucencyByDistance;\n    translucencyByDistance.x = compressedAttribute1.z;\n    translucencyByDistance.z = compressedAttribute1.w;\n    \n    translucencyByDistance.y = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n    \n    temp = compressedAttribute1.y * SHIFT_RIGHT8;\n    translucencyByDistance.w = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n#endif\n\n#ifdef ALIGNED_AXIS\n    vec3 alignedAxis = czm_octDecode(floor(compressedAttribute1.y * SHIFT_RIGHT8));\n    temp = compressedAttribute2.z * SHIFT_RIGHT5;\n    bool validAlignedAxis = (temp - floor(temp)) * SHIFT_LEFT1 > 0.0;\n#else\n    vec3 alignedAxis = vec3(0.0);\n    bool validAlignedAxis = false;\n#endif\n    \n#ifdef RENDER_FOR_PICK\n    temp = compressedAttribute2.y;\n#else\n    temp = compressedAttribute2.x;\n#endif\n\n    vec4 color;\n    temp = temp * SHIFT_RIGHT8;\n    color.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    color.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    color.r = floor(temp);\n    \n    temp = compressedAttribute2.z * SHIFT_RIGHT8;\n    bool sizeInMeters = floor((temp - floor(temp)) * SHIFT_LEFT7) > 0.0;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    \n#ifdef RENDER_FOR_PICK\n    color.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    vec4 pickColor = color / 255.0;\n#else\n    color.a = floor(temp);\n    color /= 255.0;\n#endif\n    \n    ///////////////////////////////////////////////////////////////////////////\n    \n    vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n    vec4 positionEC = czm_modelViewRelativeToEye * p;\n    positionEC = czm_eyeOffset(positionEC, eyeOffset.xyz);\n    positionEC.xyz *= show;\n    \n    ///////////////////////////////////////////////////////////////////////////     \n\n#if defined(EYE_DISTANCE_SCALING) || defined(EYE_DISTANCE_TRANSLUCENCY) || defined(EYE_DISTANCE_PIXEL_OFFSET)\n    float lengthSq;\n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        // 2D camera distance is a special case\n        // treat all billboards as flattened to the z=0.0 plane\n        lengthSq = czm_eyeHeight2D.y;\n    }\n    else\n    {\n        lengthSq = dot(positionEC.xyz, positionEC.xyz);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_SCALING\n    scale *= czm_nearFarScalar(scaleByDistance, lengthSq);\n    // push vertex behind near plane for clipping\n    if (scale == 0.0)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n    float translucency = 1.0;\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    translucency = czm_nearFarScalar(translucencyByDistance, lengthSq);\n    // push vertex behind near plane for clipping\n    if (translucency == 0.0)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_PIXEL_OFFSET\n    float pixelOffsetScale = czm_nearFarScalar(pixelOffsetScaleByDistance, lengthSq);\n    pixelOffset *= pixelOffsetScale;\n#endif\n    \n#ifdef CLAMPED_TO_GROUND\n    // move slightly closer to camera to avoid depth issues.\n    positionEC.z *= 0.995;\n    \n    // Force bottom vertical origin\n    origin.y = 1.0;\n#endif\n\n    vec4 positionWC = computePositionWindowCoordinates(positionEC, imageSize, scale, direction, origin, translate, pixelOffset, alignedAxis, validAlignedAxis, rotation, sizeInMeters);\n    gl_Position = czm_viewportOrthographic * vec4(positionWC.xy, -positionWC.z, 1.0);\n    v_textureCoordinates = textureCoordinates;\n\n#ifdef RENDER_FOR_PICK\n    v_pickColor = pickColor;\n#else\n    v_color = color;\n    v_color.a *= translucency;\n#endif\n}",

    "CompositeOITFS": "\n/**\n * Compositing for Weighted Blended Order-Independent Transparency. See:\n * - http://jcgt.org/published/0002/02/09/\n * - http://casual-effects.blogspot.com/2014/03/weighted-blended-order-independent.html\n */\n \nuniform sampler2D u_opaque;\nuniform sampler2D u_accumulation;\nuniform sampler2D u_revealage;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    vec4 opaque = texture2D(u_opaque, v_textureCoordinates);\n    vec4 accum = texture2D(u_accumulation, v_textureCoordinates);\n    float r = texture2D(u_revealage, v_textureCoordinates).r;\n    \n#ifdef MRT\n    vec4 transparent = vec4(accum.rgb / clamp(r, 1e-4, 5e4), accum.a);\n#else\n    vec4 transparent = vec4(accum.rgb / clamp(accum.a, 1e-4, 5e4), r);\n#endif\n    \n    gl_FragColor = (1.0 - transparent.a) * transparent + transparent.a * opaque;\n}\n",

    "DepthPlaneFS": "\nvarying vec4 positionEC;\n\nvoid main()\n{\n    // TODO: make arbitrary ellipsoid\n    czm_ellipsoid ellipsoid = czm_getWgs84EllipsoidEC();\n    \n    vec3 direction = normalize(positionEC.xyz);\n    czm_ray ray = czm_ray(vec3(0.0), direction);\n    \n    czm_raySegment intersection = czm_rayEllipsoidIntersectionInterval(ray, ellipsoid);\n    if (!czm_isEmpty(intersection))\n    {\n        gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);\n    }\n    else\n    {\n        discard;\n    }\n}",

    "DepthPlaneVS": "\nattribute vec4 position;\n\nvarying vec4 positionEC;\n\nvoid main()\n{\n    positionEC = czm_f_modelView * position;\n    gl_Position = czm_f_projection * positionEC;\n}",

    "EllipsoidFS": "\n#ifdef WRITE_DEPTH\n#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n#endif\n\nuniform vec3 u_radii;\nuniform vec3 u_oneOverEllipsoidRadiiSquared;\n\nvarying vec3 v_positionEC;\n\nvec4 computeEllipsoidColor(czm_ray ray, float intersection, float side)\n{\n    vec3 positionEC = czm_pointAlongRay(ray, intersection);\n    vec3 positionMC = (czm_f_inverseModelView * vec4(positionEC, 1.0)).xyz;\n    vec3 geodeticNormal = normalize(czm_geodeticSurfaceNormal(positionMC, vec3(0.0), u_oneOverEllipsoidRadiiSquared));\n    vec3 sphericalNormal = normalize(positionMC / u_radii);\n    vec3 normalMC = geodeticNormal * side;              // normalized surface normal (always facing the viewer) in model coordinates\n    vec3 normalEC = normalize(czm_f_normal * normalMC);   // normalized surface normal in eye coordiantes\n\n    vec2 st = czm_ellipsoidWgs84TextureCoordinates(sphericalNormal);\n    vec3 positionToEyeEC = -positionEC;\n\n    czm_materialInput materialInput;\n    materialInput.s = st.s;\n    materialInput.st = st;\n    materialInput.str = (positionMC + u_radii) / u_radii;\n    materialInput.normalEC = normalEC;\n    materialInput.tangentToEyeMatrix = czm_eastNorthUpToEyeCoordinates(positionMC, normalEC);\n    materialInput.positionToEyeEC = positionToEyeEC;\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef ONLY_SUN_LIGHTING\n    return czm_private_phong(normalize(positionToEyeEC), material);\n#else\n    return czm_phong(normalize(positionToEyeEC), material);\n#endif\n}\n\nvoid main()\n{\n    // PERFORMANCE_TODO: When dynamic branching is available, compute ratio of maximum and minimum radii\n    // in the vertex shader. Only when it is larger than some constant, march along the ray.\n    // Otherwise perform one intersection test which will be the common case.\n    \n    // Test if the ray intersects a sphere with the ellipsoid's maximum radius.\n    // For very oblate ellipsoids, using the ellipsoid's radii for an intersection test\n    // may cause false negatives. This will discard fragments before marching the ray forward.\n    float maxRadius = max(u_radii.x, max(u_radii.y, u_radii.z)) * 1.5;\n    vec3 direction = normalize(v_positionEC);\n    vec3 ellipsoidCenter = czm_f_modelView[3].xyz;\n    \n    float t1 = -1.0;\n    float t2 = -1.0;\n    \n    float b = -2.0 * dot(direction, ellipsoidCenter);\n    float c = dot(ellipsoidCenter, ellipsoidCenter) - maxRadius * maxRadius;\n\n    float discriminant = b * b - 4.0 * c;\n    if (discriminant >= 0.0) {\n        t1 = (-b - sqrt(discriminant)) * 0.5;\n        t2 = (-b + sqrt(discriminant)) * 0.5;\n    }\n    \n    if (t1 < 0.0 && t2 < 0.0) {\n        discard;\n    }\n    \n    float t = min(t1, t2);\n    if (t < 0.0) {\n        t = 0.0;\n    }\n    \n    // March ray forward to intersection with larger sphere and find\n    // actual intersection point with ellipsoid.\n    czm_ellipsoid ellipsoid = czm_ellipsoidNew(ellipsoidCenter, u_radii);\n    czm_ray ray = czm_ray(t * direction, direction);\n    czm_raySegment intersection = czm_rayEllipsoidIntersectionInterval(ray, ellipsoid);\n    \n    if (czm_isEmpty(intersection))\n    {\n        discard;\n    }\n\n    // If the viewer is outside, compute outsideFaceColor, with normals facing outward.\n    vec4 outsideFaceColor = (intersection.start != 0.0) ? computeEllipsoidColor(ray, intersection.start, 1.0) : vec4(0.0);\n\n    // If the viewer either is inside or can see inside, compute insideFaceColor, with normals facing inward.\n    vec4 insideFaceColor = (outsideFaceColor.a < 1.0) ? computeEllipsoidColor(ray, intersection.stop, -1.0) : vec4(0.0);\n\n    gl_FragColor = mix(insideFaceColor, outsideFaceColor, outsideFaceColor.a);\n    gl_FragColor.a = 1.0 - (1.0 - insideFaceColor.a) * (1.0 - outsideFaceColor.a);\n    \n#ifdef WRITE_DEPTH\n#ifdef GL_EXT_frag_depth\n    t = (intersection.start != 0.0) ? intersection.start : intersection.stop;\n    vec3 positionEC = czm_pointAlongRay(ray, t);\n    vec4 positionCC = czm_f_projection * vec4(positionEC, 1.0);\n    float z = positionCC.z / positionCC.w;\n    \n    float n = czm_depthRange.near;\n    float f = czm_depthRange.far;\n    \n    gl_FragDepthEXT = (z * (f - n) + f + n) * 0.5;\n#endif\n#endif\n}\n",

    "EllipsoidVS": "\nattribute vec3 position;\n\nuniform vec3 u_radii;\n\nvarying vec3 v_positionEC;\n\nvoid main() \n{\n    // In the vertex data, the cube goes from (-1.0, -1.0, -1.0) to (1.0, 1.0, 1.0) in model coordinates.\n    // Scale to consider the radii.  We could also do this once on the CPU when using the BoxGeometry,\n    // but doing it here allows us to change the radii without rewriting the vertex data, and\n    // allows all ellipsoids to reuse the same vertex data.\n    vec4 p = vec4(u_radii * position, 1.0);\n\n    v_positionEC = (czm_f_modelView * p).xyz;     // position in eye coordinates\n    gl_Position = czm_f_modelViewProjection * p;  // position in clip coordinates\n\n    // With multi-frustum, when the ellipsoid primitive is positioned on the intersection of two frustums \n    // and close to terrain, the terrain (writes depth) in the closest frustum can overwrite part of the \n    // ellipsoid (does not write depth) that was rendered in the farther frustum.\n    //\n    // Here, we clamp the depth in the vertex shader to avoid being overwritten; however, this creates\n    // artifacts since some fragments can be alpha blended twice.  This is solved by only rendering\n    // the ellipsoid in the closest frustum to the viewer.\n    gl_Position.z = clamp(gl_Position.z, czm_depthRange.near, czm_depthRange.far);\n}\n",

    "GlobeFS": "\n//#define SHOW_TILE_BOUNDARIES\n\nuniform vec4 u_initialColor;\n\n#ifdef SHOW_REFLECTIVE_OCEAN\nuniform sampler2D u_waterMask;\nuniform vec4 u_waterMaskTranslationAndScale;\nuniform float u_zoomedOutOceanSpecularIntensity;\n#endif\n\n#ifdef SHOW_OCEAN_WAVES\nuniform sampler2D u_oceanNormalMap;\n#endif\n\n#ifdef ENABLE_DAYNIGHT_SHADING\nuniform vec2 u_lightingFadeDistance;\n#endif\n\nvarying vec3 v_positionMC;\nvarying vec3 v_positionEC;\nvarying vec2 v_textureCoordinates;\nvarying vec3 v_normalMC;\nvarying vec3 v_normalEC;\n\n#ifdef FOG\nvarying float v_distance;\nvarying vec3 v_rayleighColor;\nvarying vec3 v_mieColor;\n#endif\n\nvec4 sampleAndBlend(\n    vec4 previousColor,\n    sampler2D texture,\n    vec2 tileTextureCoordinates,\n    vec4 textureCoordinateRectangle,\n    vec4 textureCoordinateTranslationAndScale,\n    float textureAlpha,\n    float textureBrightness,\n    float textureContrast,\n    float textureHue,\n    float textureSaturation,\n    float textureOneOverGamma)\n{\n    // This crazy step stuff sets the alpha to 0.0 if this following condition is true:\n    //    tileTextureCoordinates.s < textureCoordinateRectangle.s ||\n    //    tileTextureCoordinates.s > textureCoordinateRectangle.p ||\n    //    tileTextureCoordinates.t < textureCoordinateRectangle.t ||\n    //    tileTextureCoordinates.t > textureCoordinateRectangle.q\n    // In other words, the alpha is zero if the fragment is outside the rectangle\n    // covered by this texture.  Would an actual 'if' yield better performance?\n    vec2 alphaMultiplier = step(textureCoordinateRectangle.st, tileTextureCoordinates); \n    textureAlpha = textureAlpha * alphaMultiplier.x * alphaMultiplier.y;\n    \n    alphaMultiplier = step(vec2(0.0), textureCoordinateRectangle.pq - tileTextureCoordinates);\n    textureAlpha = textureAlpha * alphaMultiplier.x * alphaMultiplier.y;\n    \n    vec2 translation = textureCoordinateTranslationAndScale.xy;\n    vec2 scale = textureCoordinateTranslationAndScale.zw;\n    vec2 textureCoordinates = tileTextureCoordinates * scale + translation;\n    vec4 value = texture2D(texture, textureCoordinates);\n    vec3 color = value.rgb;\n    float alpha = value.a;\n    \n#ifdef APPLY_BRIGHTNESS\n    color = mix(vec3(0.0), color, textureBrightness);\n#endif\n\n#ifdef APPLY_CONTRAST\n    color = mix(vec3(0.5), color, textureContrast);\n#endif\n\n#ifdef APPLY_HUE\n    color = czm_hue(color, textureHue);\n#endif\n\n#ifdef APPLY_SATURATION\n    color = czm_saturation(color, textureSaturation);\n#endif\n\n#ifdef APPLY_GAMMA\n    color = pow(color, vec3(textureOneOverGamma));\n#endif\n\n    float sourceAlpha = alpha * textureAlpha;\n    float outAlpha = mix(previousColor.a, 1.0, sourceAlpha);\n    vec3 outColor = mix(previousColor.rgb * previousColor.a, color, sourceAlpha) / outAlpha;\n    return vec4(outColor, outAlpha);\n}\n\nvec4 computeDayColor(vec4 initialColor, vec2 textureCoordinates);\nvec4 computeWaterColor(vec3 positionEyeCoordinates, vec2 textureCoordinates, mat3 enuToEye, vec4 imageryColor, float specularMapValue);\n\nvoid main()\n{\n    vec4 color = computeDayColor(u_initialColor, v_textureCoordinates);\n\n#ifdef SHOW_TILE_BOUNDARIES\n    if (v_textureCoordinates.x < (1.0/256.0) || v_textureCoordinates.x > (255.0/256.0) ||\n        v_textureCoordinates.y < (1.0/256.0) || v_textureCoordinates.y > (255.0/256.0))\n    {\n        color = vec4(1.0, 0.0, 0.0, 1.0);\n    }\n#endif\n\n#if defined(SHOW_REFLECTIVE_OCEAN) || defined(ENABLE_DAYNIGHT_SHADING)\n    vec3 normalMC = normalize(czm_geodeticSurfaceNormal(v_positionMC, vec3(0.0), vec3(1.0)));   // normalized surface normal in model coordinates\n    vec3 normalEC = normalize(czm_f_normal3D * normalMC);                                         // normalized surface normal in eye coordiantes\n#endif\n\n#ifdef SHOW_REFLECTIVE_OCEAN\n    vec2 waterMaskTranslation = u_waterMaskTranslationAndScale.xy;\n    vec2 waterMaskScale = u_waterMaskTranslationAndScale.zw;\n    vec2 waterMaskTextureCoordinates = v_textureCoordinates * waterMaskScale + waterMaskTranslation;\n\n    float mask = texture2D(u_waterMask, waterMaskTextureCoordinates).r;\n\n    if (mask > 0.0)\n    {\n        mat3 enuToEye = czm_eastNorthUpToEyeCoordinates(v_positionMC, normalEC);\n        \n        vec2 ellipsoidTextureCoordinates = czm_ellipsoidWgs84TextureCoordinates(normalMC);\n        vec2 ellipsoidFlippedTextureCoordinates = czm_ellipsoidWgs84TextureCoordinates(normalMC.zyx);\n\n        vec2 textureCoordinates = mix(ellipsoidTextureCoordinates, ellipsoidFlippedTextureCoordinates, czm_a_morphTime * smoothstep(0.9, 0.95, normalMC.z));\n\n        color = computeWaterColor(v_positionEC, textureCoordinates, enuToEye, color, mask);\n    }\n#endif\n\n#ifdef ENABLE_VERTEX_LIGHTING\n    float diffuseIntensity = clamp(czm_getLambertDiffuse(czm_a_sunDirectionEC, normalize(v_normalEC)) * 0.9 + 0.3, 0.0, 1.0);\n    vec4 finalColor = vec4(color.rgb * diffuseIntensity, color.a);\n#elif defined(ENABLE_DAYNIGHT_SHADING)\n    float diffuseIntensity = clamp(czm_getLambertDiffuse(czm_a_sunDirectionEC, normalEC) * 5.0 + 0.3, 0.0, 1.0);\n    float cameraDist = length(czm_f_view[3]);\n    float fadeOutDist = u_lightingFadeDistance.x;\n    float fadeInDist = u_lightingFadeDistance.y;\n    float t = clamp((cameraDist - fadeOutDist) / (fadeInDist - fadeOutDist), 0.0, 1.0);\n    diffuseIntensity = mix(1.0, diffuseIntensity, t);\n    vec4 finalColor = vec4(color.rgb * diffuseIntensity, color.a);\n#else\n    vec4 finalColor = color;\n#endif\n\n\n#ifdef FOG\n    const float fExposure = 2.0;\n    vec3 fogColor = v_mieColor + finalColor.rgb * v_rayleighColor;\n    fogColor = vec3(1.0) - exp(-fExposure * fogColor);\n    \n    gl_FragColor = vec4(czm_fog(v_distance, finalColor.rgb, fogColor), finalColor.a);\n#else\n    gl_FragColor = finalColor;\n#endif\n}\n\n#ifdef SHOW_REFLECTIVE_OCEAN\n\nfloat waveFade(float edge0, float edge1, float x)\n{\n    float y = clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0);\n    return pow(1.0 - y, 5.0);\n}\n\nfloat linearFade(float edge0, float edge1, float x)\n{\n    return clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0);\n}\n\n// Based on water rendering by Jonas Wagner:\n// http://29a.ch/2012/7/19/webgl-terrain-rendering-water-fog\n\n// low altitude wave settings\nconst float oceanFrequencyLowAltitude = 825000.0;\nconst float oceanAnimationSpeedLowAltitude = 0.004;\nconst float oceanOneOverAmplitudeLowAltitude = 1.0 / 2.0;\nconst float oceanSpecularIntensity = 0.5;\n \n// high altitude wave settings\nconst float oceanFrequencyHighAltitude = 125000.0;\nconst float oceanAnimationSpeedHighAltitude = 0.008;\nconst float oceanOneOverAmplitudeHighAltitude = 1.0 / 2.0;\n\nvec4 computeWaterColor(vec3 positionEyeCoordinates, vec2 textureCoordinates, mat3 enuToEye, vec4 imageryColor, float maskValue)\n{\n    vec3 positionToEyeEC = -positionEyeCoordinates;\n    float positionToEyeECLength = length(positionToEyeEC);\n\n    // The double normalize below works around a bug in Firefox on Android devices.\n    vec3 normalizedpositionToEyeEC = normalize(normalize(positionToEyeEC));\n    \n    // Fade out the waves as the camera moves far from the surface.\n    float waveIntensity = waveFade(70000.0, 1000000.0, positionToEyeECLength);\n\n#ifdef SHOW_OCEAN_WAVES\n    // high altitude waves\n    float time = czm_a_frameNumber * oceanAnimationSpeedHighAltitude;\n    vec4 noise = czm_getWaterNoise(u_oceanNormalMap, textureCoordinates * oceanFrequencyHighAltitude, time, 0.0);\n    vec3 normalTangentSpaceHighAltitude = vec3(noise.xy, noise.z * oceanOneOverAmplitudeHighAltitude);\n    \n    // low altitude waves\n    time = czm_a_frameNumber * oceanAnimationSpeedLowAltitude;\n    noise = czm_getWaterNoise(u_oceanNormalMap, textureCoordinates * oceanFrequencyLowAltitude, time, 0.0);\n    vec3 normalTangentSpaceLowAltitude = vec3(noise.xy, noise.z * oceanOneOverAmplitudeLowAltitude);\n    \n    // blend the 2 wave layers based on distance to surface\n    float highAltitudeFade = linearFade(0.0, 60000.0, positionToEyeECLength);\n    float lowAltitudeFade = 1.0 - linearFade(20000.0, 60000.0, positionToEyeECLength);\n    vec3 normalTangentSpace = \n        (highAltitudeFade * normalTangentSpaceHighAltitude) + \n        (lowAltitudeFade * normalTangentSpaceLowAltitude);\n    normalTangentSpace = normalize(normalTangentSpace);\n    \n    // fade out the normal perturbation as we move farther from the water surface\n    normalTangentSpace.xy *= waveIntensity;\n    normalTangentSpace = normalize(normalTangentSpace);\n#else\n    vec3 normalTangentSpace = vec3(0.0, 0.0, 1.0);\n#endif\n\n    vec3 normalEC = enuToEye * normalTangentSpace;\n    \n    const vec3 waveHighlightColor = vec3(0.3, 0.45, 0.6);\n    \n    // Use diffuse light to highlight the waves\n    float diffuseIntensity = czm_getLambertDiffuse(czm_a_sunDirectionEC, normalEC) * maskValue;\n    vec3 diffuseHighlight = waveHighlightColor * diffuseIntensity;\n    \n#ifdef SHOW_OCEAN_WAVES\n    // Where diffuse light is low or non-existent, use wave highlights based solely on\n    // the wave bumpiness and no particular light direction.\n    float tsPerturbationRatio = normalTangentSpace.z;\n    vec3 nonDiffuseHighlight = mix(waveHighlightColor * 5.0 * (1.0 - tsPerturbationRatio), vec3(0.0), diffuseIntensity);\n#else\n    vec3 nonDiffuseHighlight = vec3(0.0);\n#endif\n\n    // Add specular highlights in 3D, and in all modes when zoomed in.\n    float specularIntensity = czm_getSpecular(czm_a_sunDirectionEC, normalizedpositionToEyeEC, normalEC, 10.0) + 0.25 * czm_getSpecular(czm_a_moonDirectionEC, normalizedpositionToEyeEC, normalEC, 10.0);\n    float surfaceReflectance = mix(0.0, mix(u_zoomedOutOceanSpecularIntensity, oceanSpecularIntensity, waveIntensity), maskValue);\n    float specular = specularIntensity * surfaceReflectance;\n    \n    return vec4(imageryColor.rgb + diffuseHighlight + nonDiffuseHighlight + specular, imageryColor.a); \n}\n\n#endif // #ifdef SHOW_REFLECTIVE_OCEAN\n",

    "GlobeVS": "#ifdef QUANTIZATION_BITS12\nattribute vec4 compressed;\n#else\nattribute vec4 position3DAndHeight;\nattribute vec3 textureCoordAndEncodedNormals;\n#endif\n\nuniform vec3 u_center3D;\nuniform mat4 u_modifiedModelView;\nuniform vec4 u_tileRectangle;\n\n// Uniforms for 2D Mercator projection\nuniform vec2 u_southAndNorthLatitude;\nuniform vec2 u_southMercatorYAndOneOverHeight;\n\nvarying vec3 v_positionMC;\nvarying vec3 v_positionEC;\n\nvarying vec2 v_textureCoordinates;\nvarying vec3 v_normalMC;\nvarying vec3 v_normalEC;\n\n#ifdef FOG\nvarying float v_distance;\nvarying vec3 v_mieColor;\nvarying vec3 v_rayleighColor;\n#endif\n\n// These functions are generated at runtime.\nvec4 getPosition(vec3 position, float height, vec2 textureCoordinates);\nfloat get2DYPositionFraction(vec2 textureCoordinates);\n\nvec4 getPosition3DMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    return czm_f_projection * (u_modifiedModelView * vec4(position, 1.0));\n}\n\nfloat get2DMercatorYPositionFraction(vec2 textureCoordinates)\n{\n    // The width of a tile at level 11, in radians and assuming a single root tile, is\n    //   2.0 * czm_pi / pow(2.0, 11.0)\n    // We want to just linearly interpolate the 2D position from the texture coordinates\n    // when we're at this level or higher.  The constant below is the expression\n    // above evaluated and then rounded up at the 4th significant digit.\n    const float maxTileWidth = 0.003068;\n    float positionFraction = textureCoordinates.y;\n    float southLatitude = u_southAndNorthLatitude.x;\n    float northLatitude = u_southAndNorthLatitude.y;\n    if (northLatitude - southLatitude > maxTileWidth)\n    {\n        float southMercatorY = u_southMercatorYAndOneOverHeight.x;\n        float oneOverMercatorHeight = u_southMercatorYAndOneOverHeight.y;\n\n        float currentLatitude = mix(southLatitude, northLatitude, textureCoordinates.y);\n        currentLatitude = clamp(currentLatitude, -czm_webMercatorMaxLatitude, czm_webMercatorMaxLatitude);\n        positionFraction = czm_latitudeToWebMercatorFraction(currentLatitude, southMercatorY, oneOverMercatorHeight);\n    }    \n    return positionFraction;\n}\n\nfloat get2DGeographicYPositionFraction(vec2 textureCoordinates)\n{\n    return textureCoordinates.y;\n}\n\nvec4 getPositionPlanarEarth(vec3 position, float height, vec2 textureCoordinates)\n{\n    float yPositionFraction = get2DYPositionFraction(textureCoordinates);\n    vec4 rtcPosition2D = vec4(height, mix(u_tileRectangle.st, u_tileRectangle.pq, vec2(textureCoordinates.x, yPositionFraction)), 1.0);\n    return czm_f_projection * (u_modifiedModelView * rtcPosition2D);\n}\n\nvec4 getPosition2DMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    return getPositionPlanarEarth(position, 0.0, textureCoordinates);\n}\n\nvec4 getPositionColumbusViewMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    return getPositionPlanarEarth(position, height, textureCoordinates);\n}\n\nvec4 getPositionMorphingMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    // We do not do RTC while morphing, so there is potential for jitter.\n    // This is unlikely to be noticeable, though.\n    vec3 position3DWC = position + u_center3D;\n    float yPositionFraction = get2DYPositionFraction(textureCoordinates);\n    vec4 position2DWC = vec4(height, mix(u_tileRectangle.st, u_tileRectangle.pq, vec2(textureCoordinates.x, yPositionFraction)), 1.0);\n    vec4 morphPosition = czm_columbusViewMorph(position2DWC, vec4(position3DWC, 1.0), czm_a_morphTime);\n    return czm_f_modelViewProjection * morphPosition;\n}\n\n#ifdef QUANTIZATION_BITS12\nuniform vec2 u_minMaxHeight;\nuniform mat4 u_scaleAndBias;\n#endif\n\nvoid main() \n{\n#ifdef QUANTIZATION_BITS12\n    vec2 xy = czm_decompressTextureCoordinates(compressed.x);\n    vec2 zh = czm_decompressTextureCoordinates(compressed.y);\n    vec3 position = vec3(xy, zh.x);\n    float height = zh.y;\n    vec2 textureCoordinates = czm_decompressTextureCoordinates(compressed.z);\n    float encodedNormal = compressed.w;\n\n    height = height * (u_minMaxHeight.y - u_minMaxHeight.x) + u_minMaxHeight.x;\n    position = (u_scaleAndBias * vec4(position, 1.0)).xyz;\n#else\n    vec3 position = position3DAndHeight.xyz;\n    float height = position3DAndHeight.w;\n    vec2 textureCoordinates = textureCoordAndEncodedNormals.xy;\n    float encodedNormal = textureCoordAndEncodedNormals.z;\n#endif\n\n    vec3 position3DWC = position + u_center3D;\n    gl_Position = getPosition(position, height, textureCoordinates);\n\n    v_textureCoordinates = textureCoordinates;\n\n#if defined(ENABLE_VERTEX_LIGHTING)\n    v_positionEC = (czm_f_modelView3D * vec4(position3DWC, 1.0)).xyz;\n    v_positionMC = position3DWC;                                 // position in model coordinates\n    v_normalMC = czm_octDecode(encodedNormal);\n    v_normalEC = czm_f_normal3D * v_normalMC;\n#elif defined(SHOW_REFLECTIVE_OCEAN) || defined(ENABLE_DAYNIGHT_SHADING)\n    v_positionEC = (czm_f_modelView3D * vec4(position3DWC, 1.0)).xyz;\n    v_positionMC = position3DWC;                                 // position in model coordinates\n#endif\n    \n#ifdef FOG\n    AtmosphereColor atmosColor = computeGroundAtmosphereFromSpace(position3DWC);\n    v_mieColor = atmosColor.mie;\n    v_rayleighColor = atmosColor.rayleigh;\n    v_distance = length((czm_f_modelView3D * vec4(position3DWC, 1.0)).xyz);\n#endif\n}",

    "GroundAtmosphere": "\n/*!\n * Atmosphere code:\n *\n * Copyright (c) 2000-2005, Sean O'Neil (s_p_oneil@hotmail.com)\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * \n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n * * Neither the name of the project nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS 'AS IS'\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * Modifications made by Analytical Graphics, Inc.\n */\n \n // Atmosphere:\n //   Code:  http://sponeil.net/\n //   GPU Gems 2 Article:  http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter16.html\n\nconst float u_innerRadius = 6378137.0;\nconst float u_outerRadius = 6378137.0 * 1.025;\nconst float u_outerRadius2 = u_outerRadius * u_outerRadius;\n\nconst float Kr = 0.0025;\nconst float Km = 0.0015;\nconst float ESun = 15.0;\n\nconst float fKrESun = Kr * ESun;\nconst float fKmESun = Km * ESun;\nconst float fKr4PI = Kr * 4.0 * czm_pi;\nconst float fKm4PI = Km * 4.0 * czm_pi;\n\nconst float u_scale = 1.0 / (u_outerRadius - u_innerRadius);\nconst float u_scaleDepth = 0.25;\nconst float u_scaleOverScaleDepth = u_scale / u_scaleDepth;\n\nstruct AtmosphereColor\n{\n    vec3 mie;\n    vec3 rayleigh;\n};\n\nconst int nSamples = 2;\nconst float fSamples = 2.0;\n\nfloat scale(float fCos)\n{\n    float x = 1.0 - fCos;\n    return u_scaleDepth * exp(-0.00287 + x*(0.459 + x*(3.83 + x*(-6.80 + x*5.25))));\n}\n\nAtmosphereColor computeGroundAtmosphereFromSpace(vec3 v3Pos)\n{\n vec3 v3InvWavelength = vec3(1.0 / pow(0.650, 4.0), 1.0 / pow(0.570, 4.0), 1.0 / pow(0.475, 4.0));\n\n    // Get the ray from the camera to the vertex and its length (which is the far point of the ray passing through the atmosphere)\n    vec3 v3Ray = v3Pos - czm_a_viewerPositionWC;\n    float fFar = length(v3Ray);\n    v3Ray /= fFar;\n    \n    float u_cameraHeight = length(czm_a_viewerPositionWC);\n    float u_cameraHeight2 = u_cameraHeight * u_cameraHeight;\n\n    // This next line is an ANGLE workaround. It is equivalent to B = 2.0 * dot(czm_a_viewerPositionWC, v3Ray), \n    // which is what it should be, but there are problems at the poles.\n    float B = 2.0 * length(czm_a_viewerPositionWC) * dot(normalize(czm_a_viewerPositionWC), v3Ray);\n    float C = u_cameraHeight2 - u_outerRadius2;\n    float fDet = max(0.0, B*B - 4.0 * C);\n    float fNear = 0.5 * (-B - sqrt(fDet));\n\n    // Calculate the ray's starting position, then calculate its scattering offset\n    vec3 v3Start = czm_a_viewerPositionWC + v3Ray * fNear;\n    fFar -= fNear;\n    float fDepth = exp((u_innerRadius - u_outerRadius) / u_scaleDepth);\n    \n    // The light angle based on the sun position would be:\n    //    dot(czm_a_sunDirectionWC, v3Pos) / length(v3Pos);\n    // We want the atmosphere to be uniform over the globe so it is set to 1.0.\n    float fLightAngle = 1.0;\n    float fCameraAngle = dot(-v3Ray, v3Pos) / length(v3Pos);\n    float fCameraScale = scale(fCameraAngle);\n    float fLightScale = scale(fLightAngle);\n    float fCameraOffset = fDepth*fCameraScale;\n    float fTemp = (fLightScale + fCameraScale);\n\n    // Initialize the scattering loop variables\n    float fSampleLength = fFar / fSamples;\n    float u_scaledLength = fSampleLength * u_scale;\n    vec3 v3SampleRay = v3Ray * fSampleLength;\n    vec3 v3SamplePoint = v3Start + v3SampleRay * 0.5;\n\n    // Now loop through the sample rays\n    vec3 v3FrontColor = vec3(0.0);\n    vec3 v3Attenuate = vec3(0.0);\n    for(int i=0; i<nSamples; i++)\n    {\n        float fHeight = length(v3SamplePoint);\n        float fDepth = exp(u_scaleOverScaleDepth * (u_innerRadius - fHeight));\n        float fScatter = fDepth*fTemp - fCameraOffset;\n        v3Attenuate = exp(-fScatter * (v3InvWavelength * fKr4PI + fKm4PI));\n        v3FrontColor += v3Attenuate * (fDepth * u_scaledLength);\n        v3SamplePoint += v3SampleRay;\n    }\n    \n    AtmosphereColor color;\n    color.mie = v3FrontColor * (v3InvWavelength * fKrESun + fKmESun);\n    color.rayleigh = v3Attenuate; // Calculate the attenuation factor for the ground\n    \n    return color;\n}\n\n",

    "PointPrimitiveCollectionFS": "\nvarying vec4 v_color;\nvarying vec4 v_outlineColor;\nvarying float v_innerPercent;\nvarying float v_pixelDistance;\n\n#ifdef RENDER_FOR_PICK\nvarying vec4 v_pickColor;\n#endif\n\nvoid main()\n{\n    // The distance in UV space from this fragment to the center of the point, at most 0.5.\n    float distanceToCenter = length(gl_PointCoord - vec2(0.5));\n    // The max distance stops one pixel shy of the edge to leave space for anti-aliasing.\n    float maxDistance = max(0.0, 0.5 - v_pixelDistance);\n    float wholeAlpha = 1.0 - smoothstep(maxDistance, 0.5, distanceToCenter);\n    float innerAlpha = 1.0 - smoothstep(maxDistance * v_innerPercent, 0.5 * v_innerPercent, distanceToCenter);\n\n    vec4 color = mix(v_outlineColor, v_color, innerAlpha);\n    color.a *= wholeAlpha;\n    if (color.a < 0.005)\n    {\n        discard;\n    }\n\n#ifdef RENDER_FOR_PICK\n    gl_FragColor = v_pickColor;\n#else\n    gl_FragColor = color;\n#endif\n}",

    "PointPrimitiveCollectionVS": "\nuniform float u_maxTotalPointSize;\n\nattribute vec4 positionHighAndSize;\nattribute vec4 positionLowAndOutline;\nattribute vec4 compressedAttribute0;        // color, outlineColor, pick color\nattribute vec4 compressedAttribute1;        // show, translucency by distance, some free space\nattribute vec4 scaleByDistance;             // near, nearScale, far, farScale\n\nvarying vec4 v_color;\nvarying vec4 v_outlineColor;\nvarying float v_innerPercent;\nvarying float v_pixelDistance;\n\n#ifdef RENDER_FOR_PICK\nvarying vec4 v_pickColor;\n#endif\n\nconst float SHIFT_LEFT8 = 256.0;\nconst float SHIFT_RIGHT8 = 1.0 / 256.0;\n\nvoid main()\n{\n    // Modifying this shader may also require modifications to PointPrimitive._computeScreenSpacePosition\n\n    // unpack attributes\n    vec3 positionHigh = positionHighAndSize.xyz;\n    vec3 positionLow = positionLowAndOutline.xyz;\n    float outlineWidthBothSides = 2.0 * positionLowAndOutline.w;\n    float totalSize = positionHighAndSize.w + outlineWidthBothSides;\n    float outlinePercent = outlineWidthBothSides / totalSize;\n    // Scale in response to browser-zoom.\n    totalSize *= czm_resolutionScale;\n    // Add padding for anti-aliasing on both sides.\n    totalSize += 3.0;\n\n    float temp = compressedAttribute1.x * SHIFT_RIGHT8;\n    float show = floor(temp);\n\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    vec4 translucencyByDistance;\n    translucencyByDistance.x = compressedAttribute1.z;\n    translucencyByDistance.z = compressedAttribute1.w;\n\n    translucencyByDistance.y = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n\n    temp = compressedAttribute1.y * SHIFT_RIGHT8;\n    translucencyByDistance.w = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n#endif\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 color;\n    vec4 outlineColor;\n#ifdef RENDER_FOR_PICK\n    // compressedAttribute0.z => pickColor.rgb\n\n    color = vec4(0.0);\n    outlineColor = vec4(0.0);\n    vec4 pickColor;\n    temp = compressedAttribute0.z * SHIFT_RIGHT8;\n    pickColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    pickColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor.r = floor(temp);\n#else\n    // compressedAttribute0.x => color.rgb\n\n    temp = compressedAttribute0.x * SHIFT_RIGHT8;\n    color.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    color.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    color.r = floor(temp);\n\n    // compressedAttribute0.y => outlineColor.rgb\n\n    temp = compressedAttribute0.y * SHIFT_RIGHT8;\n    outlineColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor.r = floor(temp);\n#endif\n\n    // compressedAttribute0.w => color.a, outlineColor.a, pickColor.a\n\n    temp = compressedAttribute0.w * SHIFT_RIGHT8;\n#ifdef RENDER_FOR_PICK\n    pickColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor = pickColor / 255.0;\n#endif\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor /= 255.0;\n    color.a = floor(temp);\n    color /= 255.0;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n    vec4 positionEC = czm_modelViewRelativeToEye * p;\n    positionEC.xyz *= show;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n#if defined(EYE_DISTANCE_SCALING) || defined(EYE_DISTANCE_TRANSLUCENCY)\n    float lengthSq;\n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        // 2D camera distance is a special case\n        // treat all billboards as flattened to the z=0.0 plane\n        lengthSq = czm_eyeHeight2D.y;\n    }\n    else\n    {\n        lengthSq = dot(positionEC.xyz, positionEC.xyz);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_SCALING\n    totalSize *= czm_nearFarScalar(scaleByDistance, lengthSq);\n#endif\n    // Clamp to max point size.\n    totalSize = min(totalSize, u_maxTotalPointSize);\n    // If size is too small, push vertex behind near plane for clipping.\n    // Note that context.minimumAliasedPointSize 'will be at most 1.0'.\n    if (totalSize < 1.0)\n    {\n        positionEC.xyz = vec3(0.0);\n        totalSize = 1.0;\n    }\n\n    float translucency = 1.0;\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    translucency = czm_nearFarScalar(translucencyByDistance, lengthSq);\n    // push vertex behind near plane for clipping\n    if (translucency < 0.004)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n    vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n\n    gl_Position = czm_f_viewportOrthographic * vec4(positionWC.xy, -positionWC.z, 1.0);\n\n    v_color = color;\n    v_color.a *= translucency;\n    v_outlineColor = outlineColor;\n    v_outlineColor.a *= translucency;\n\n    v_innerPercent = 1.0 - outlinePercent;\n    v_pixelDistance = 2.0 / totalSize;\n    gl_PointSize = totalSize;\n\n#ifdef RENDER_FOR_PICK\n    v_pickColor = pickColor;\n#endif\n}\n",

    "PolylineCommon": "void clipLineSegmentToNearPlane(\n    vec3 p0,\n    vec3 p1,\n    out vec4 positionWC,\n    out bool clipped,\n    out bool culledByNearPlane)\n{\n    culledByNearPlane = false;\n    clipped = false;\n    \n    vec3 p1ToP0 = p1 - p0;\n    float magnitude = length(p1ToP0);\n    vec3 direction = normalize(p1ToP0);\n    float endPoint0Distance =  -(czm_currentFrustum.x + p0.z);\n    float denominator = -direction.z;\n    \n    if (endPoint0Distance < 0.0 && abs(denominator) < czm_epsilon7)\n    {\n        culledByNearPlane = true;\n    }\n    else if (endPoint0Distance < 0.0 && abs(denominator) > czm_epsilon7)\n    {\n        // t = (-plane distance - dot(plane normal, ray origin)) / dot(plane normal, ray direction)\n        float t = (czm_currentFrustum.x + p0.z) / denominator;\n        if (t < 0.0 || t > magnitude)\n        {\n            culledByNearPlane = true;\n        }\n        else\n        {\n            p0 = p0 + t * direction;\n            clipped = true;\n        }\n    }\n    \n    positionWC = czm_eyeToWindowCoordinates(vec4(p0, 1.0));\n}\n\nvec4 getPolylineWindowCoordinates(vec4 position, vec4 previous, vec4 next, float expandDirection, float width, bool usePrevious) {\n    vec4 endPointWC, p0, p1;\n    bool culledByNearPlane, clipped;\n    \n    vec4 positionEC = czm_modelViewRelativeToEye * position;\n    vec4 prevEC = czm_modelViewRelativeToEye * previous;\n    vec4 nextEC = czm_modelViewRelativeToEye * next;\n    \n    clipLineSegmentToNearPlane(prevEC.xyz, positionEC.xyz, p0, clipped, culledByNearPlane);\n    clipLineSegmentToNearPlane(nextEC.xyz, positionEC.xyz, p1, clipped, culledByNearPlane);\n    clipLineSegmentToNearPlane(positionEC.xyz, usePrevious ? prevEC.xyz : nextEC.xyz, endPointWC, clipped, culledByNearPlane);\n    \n    if (culledByNearPlane)\n    {\n        return vec4(0.0, 0.0, 0.0, 1.0);\n    }\n    \n    vec2 prevWC = normalize(p0.xy - endPointWC.xy);\n    vec2 nextWC = normalize(p1.xy - endPointWC.xy);\n    \n    float expandWidth = width * 0.5;\n    vec2 direction;\n\n    if (czm_equalsEpsilon(previous.xyz - position.xyz, vec3(0.0), czm_epsilon1) || czm_equalsEpsilon(prevWC, -nextWC, czm_epsilon1))\n    {\n        direction = vec2(-nextWC.y, nextWC.x);\n    }\n    else if (czm_equalsEpsilon(next.xyz - position.xyz, vec3(0.0), czm_epsilon1) || clipped)\n    {\n        direction = vec2(prevWC.y, -prevWC.x);\n    }\n    else\n    {\n        vec2 normal = vec2(-nextWC.y, nextWC.x);\n        direction = normalize((nextWC + prevWC) * 0.5);\n        if (dot(direction, normal) < 0.0)\n        {\n            direction = -direction;\n        }\n\n        // The sine of the angle between the two vectors is given by the formula\n        //         |a x b| = |a||b|sin(theta)\n        // which is\n        //     float sinAngle = length(cross(vec3(direction, 0.0), vec3(nextWC, 0.0)));\n        // Because the z components of both vectors are zero, the x and y coordinate will be zero.\n        // Therefore, the sine of the angle is just the z component of the cross product.\n        float sinAngle = abs(direction.x * nextWC.y - direction.y * nextWC.x);\n        expandWidth = clamp(expandWidth / sinAngle, 0.0, width * 2.0);\n    }\n\n    vec2 offset = direction * expandDirection * expandWidth * czm_resolutionScale;\n    return vec4(endPointWC.xy + offset, -endPointWC.z, 1.0);\n}",

    "PolylineFS": "\nvarying vec2 v_st;\n\nvoid main()\n{\n    czm_materialInput materialInput;\n    \n    materialInput.s = v_st.s;\n    materialInput.st = v_st;\n    materialInput.str = vec3(v_st, 0.0);\n    \n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n}",

    "PolylineVS": "\nattribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 position2DHigh;\nattribute vec3 position2DLow;\nattribute vec3 prevPosition3DHigh;\nattribute vec3 prevPosition3DLow;\nattribute vec3 prevPosition2DHigh;\nattribute vec3 prevPosition2DLow;\nattribute vec3 nextPosition3DHigh;\nattribute vec3 nextPosition3DLow;\nattribute vec3 nextPosition2DHigh;\nattribute vec3 nextPosition2DLow;\nattribute vec4 texCoordExpandWidthAndShow;\nattribute vec4 pickColor;\n\nvarying vec2  v_st;\nvarying float v_width;\nvarying vec4  czm_pickColor;\n\nvoid main() \n{\n    float texCoord = texCoordExpandWidthAndShow.x;\n    float expandDir = texCoordExpandWidthAndShow.y;\n    float width = abs(texCoordExpandWidthAndShow.z) + 0.5;\n    bool usePrev = texCoordExpandWidthAndShow.z < 0.0;\n    float show = texCoordExpandWidthAndShow.w;\n    \n    vec4 p, prev, next;\n    if (czm_a_morphTime == 1.0)\n    {\n        p = czm_translateRelativeToEye(position3DHigh.xyz, position3DLow.xyz);\n        prev = czm_translateRelativeToEye(prevPosition3DHigh.xyz, prevPosition3DLow.xyz);\n        next = czm_translateRelativeToEye(nextPosition3DHigh.xyz, nextPosition3DLow.xyz);\n    }\n    else if (czm_a_morphTime == 0.0)\n    {\n        p = czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy);\n        prev = czm_translateRelativeToEye(prevPosition2DHigh.zxy, prevPosition2DLow.zxy);\n        next = czm_translateRelativeToEye(nextPosition2DHigh.zxy, nextPosition2DLow.zxy);\n    }\n    else\n    {\n        p = czm_columbusViewMorph(\n                czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy),\n                czm_translateRelativeToEye(position3DHigh.xyz, position3DLow.xyz),\n                czm_a_morphTime);\n        prev = czm_columbusViewMorph(\n                czm_translateRelativeToEye(prevPosition2DHigh.zxy, prevPosition2DLow.zxy),\n                czm_translateRelativeToEye(prevPosition3DHigh.xyz, prevPosition3DLow.xyz),\n                czm_a_morphTime);\n        next = czm_columbusViewMorph(\n                czm_translateRelativeToEye(nextPosition2DHigh.zxy, nextPosition2DLow.zxy),\n                czm_translateRelativeToEye(nextPosition3DHigh.xyz, nextPosition3DLow.xyz),\n                czm_a_morphTime);\n    }\n    \n    vec4 positionWC = getPolylineWindowCoordinates(p, prev, next, expandDir, width, usePrev);\n    gl_Position = czm_f_viewportOrthographic * positionWC * show;\n    \n    v_st = vec2(texCoord, clamp(expandDir, 0.0, 1.0));\n    v_width = width;\n    czm_pickColor = pickColor;\n}\n",

    "ReprojectWebMercatorFS": "\nuniform sampler2D u_texture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = texture2D(u_texture, v_textureCoordinates);\n}\n",

    "ReprojectWebMercatorVS": "\nattribute vec4 position;\nattribute float webMercatorT;\n\nuniform mat4 u_viewportOrthographic;\nuniform vec2 u_textureDimensions;\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    v_textureCoordinates = vec2(position.x, webMercatorT);\n    gl_Position = u_viewportOrthographic * (position * vec4(u_textureDimensions, 1.0, 1.0));\n}\n",

    "ShadowVolumeFS": "\n#extension GL_EXT_frag_depth : enable\n\n// emulated noperspective\nvarying float v_WindowZ;\nvarying vec4 v_color;\n\nvoid writeDepthClampedToFarPlane()\n{\n    gl_FragDepthEXT = min(v_WindowZ * gl_FragCoord.w, 1.0);\n}\n\nvoid main(void)\n{\n    gl_FragColor = v_color;\n    writeDepthClampedToFarPlane();\n}",

    "ShadowVolumeVS": "\nattribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec4 color;\n\n// emulated noperspective\nvarying float v_WindowZ;\nvarying vec4 v_color;\n\nvec4 depthClampFarPlane(vec4 vertexInClipCoordinates)\n{\n    v_WindowZ = (0.5 * (vertexInClipCoordinates.z / vertexInClipCoordinates.w) + 0.5) * vertexInClipCoordinates.w;\n    vertexInClipCoordinates.z = min(vertexInClipCoordinates.z, vertexInClipCoordinates.w);\n    return vertexInClipCoordinates;\n}\n\nvoid main()\n{\n    v_color = color;\n    \n    vec4 position = czm_computePosition();\n    gl_Position = depthClampFarPlane(czm_modelViewProjectionRelativeToEye * position);\n}\n",

    "SkyAtmosphereFS": "\n/**\n * @license\n * Copyright (c) 2000-2005, Sean O'Neil (s_p_oneil@hotmail.com)\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * \n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n * * Neither the name of the project nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS 'AS IS'\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * Modifications made by Analytical Graphics, Inc.\n */\n \n // Code:  http://sponeil.net/\n // GPU Gems 2 Article:  http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter16.html\n \nconst float g = -0.95;\nconst float g2 = g * g;\n\nvarying vec3 v_rayleighColor;\nvarying vec3 v_mieColor;\nvarying vec3 v_toCamera;\nvarying vec3 v_positionEC;\n\nvoid main (void)\n{\n    // Extra normalize added for Android\n    float fCos = dot(czm_a_sunDirectionWC, normalize(v_toCamera)) / length(v_toCamera);\n    float fRayleighPhase = 0.75 * (1.0 + fCos * fCos);\n    float fMiePhase = 1.5 * ((1.0 - g2) / (2.0 + g2)) * (1.0 + fCos * fCos) / pow(1.0 + g2 - 2.0 * g * fCos, 1.5);\n    \n    const float fExposure = 2.0;\n    \n    vec3 rgb = fRayleighPhase * v_rayleighColor + fMiePhase * v_mieColor;\n    rgb = vec3(1.0) - exp(-fExposure * rgb);\n    float l = czm_luminance(rgb);\n    gl_FragColor = vec4(rgb, min(smoothstep(0.0, 0.1, l), 1.0) * smoothstep(0.0, 1.0, czm_a_morphTime));\n}\n",

    "SkyAtmosphereVS": "\n/**\n * @license\n * Copyright (c) 2000-2005, Sean O'Neil (s_p_oneil@hotmail.com)\n * All rights reserved.\n * \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * \n * * Redistributions of source code must retain the above copyright notice,\n *   this list of conditions and the following disclaimer.\n * * Redistributions in binary form must reproduce the above copyright notice,\n *   this list of conditions and the following disclaimer in the documentation\n *   and/or other materials provided with the distribution.\n * * Neither the name of the project nor the names of its contributors may be\n *   used to endorse or promote products derived from this software without\n *   specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS 'AS IS'\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * Modifications made by Analytical Graphics, Inc.\n */\n \n // Code:  http://sponeil.net/\n // GPU Gems 2 Article:  http://http.developer.nvidia.com/GPUGems2/gpugems2_chapter16.html\n  \nattribute vec4 position;\n\nuniform float u_cameraHeight;\nuniform float u_cameraHeight2;\nuniform float u_outerRadius;     // The outer (atmosphere) radius\nuniform float u_outerRadius2;    // u_outerRadius^2\nuniform float u_innerRadius;     // The inner (planetary) radius\nuniform float u_scale;           // 1 / (u_outerRadius - u_innerRadius)\nuniform float u_scaleDepth;      // The scale depth (i.e. the altitude at which the atmosphere's average density is found)\nuniform float u_scaleOverScaleDepth; // u_scale / u_scaleDepth\n\nconst float Kr = 0.0025;\nconst float fKr4PI = Kr * 4.0 * czm_pi;\nconst float Km = 0.0015;\nconst float fKm4PI = Km * 4.0 * czm_pi;\nconst float ESun = 15.0;\nconst float fKmESun = Km * ESun;\nconst float fKrESun = Kr * ESun;\nconst vec3 v3InvWavelength = vec3(\n    5.60204474633241,  // Red = 1.0 / Math.pow(0.650, 4.0)\n    9.473284437923038, // Green = 1.0 / Math.pow(0.570, 4.0)\n    19.643802610477206); // Blue = 1.0 / Math.pow(0.475, 4.0)\nconst float rayleighScaleDepth = 0.25;\n          \nconst int nSamples = 2;\nconst float fSamples = 2.0;\n\nvarying vec3 v_rayleighColor;\nvarying vec3 v_mieColor;\nvarying vec3 v_toCamera;\n\nfloat scale(float fCos)\n{\n    float x = 1.0 - fCos;\n    return u_scaleDepth * exp(-0.00287 + x*(0.459 + x*(3.83 + x*(-6.80 + x*5.25))));\n}\n\nvoid main(void)\n{\n    // Get the ray from the camera to the vertex and its length (which is the far point of the ray passing through the atmosphere)\n    vec3 v3Pos = position.xyz;\n    vec3 v3Ray = v3Pos - czm_a_viewerPositionWC;\n    float fFar = length(v3Ray);\n    v3Ray /= fFar;\n\n#ifdef SKY_FROM_SPACE\n    // Calculate the closest intersection of the ray with the outer atmosphere (which is the near point of the ray passing through the atmosphere)\n    float B = 2.0 * dot(czm_a_viewerPositionWC, v3Ray);\n    float C = u_cameraHeight2 - u_outerRadius2;\n    float fDet = max(0.0, B*B - 4.0 * C);\n    float fNear = 0.5 * (-B - sqrt(fDet));\n\n    // Calculate the ray's starting position, then calculate its scattering offset\n    vec3 v3Start = czm_a_viewerPositionWC + v3Ray * fNear;\n    fFar -= fNear;\n    float fStartAngle = dot(v3Ray, v3Start) / u_outerRadius;\n    float fStartDepth = exp(-1.0 / u_scaleDepth);\n    float fStartOffset = fStartDepth*scale(fStartAngle);\n#else // SKY_FROM_ATMOSPHERE\n    // Calculate the ray's starting position, then calculate its scattering offset\n    vec3 v3Start = czm_a_viewerPositionWC;\n    float fHeight = length(v3Start);\n    float fDepth = exp(u_scaleOverScaleDepth * (u_innerRadius - u_cameraHeight));\n    float fStartAngle = dot(v3Ray, v3Start) / fHeight;\n    float fStartOffset = fDepth*scale(fStartAngle);\n#endif\n\n    // Initialize the scattering loop variables\n    float fSampleLength = fFar / fSamples;\n    float u_scaledLength = fSampleLength * u_scale;\n    vec3 v3SampleRay = v3Ray * fSampleLength;\n    vec3 v3SamplePoint = v3Start + v3SampleRay * 0.5;\n\n    // Now loop through the sample rays\n    vec3 v3FrontColor = vec3(0.0, 0.0, 0.0);\n    for(int i=0; i<nSamples; i++)\n    {\n        float fHeight = length(v3SamplePoint);\n        float fDepth = exp(u_scaleOverScaleDepth * (u_innerRadius - fHeight));\n        vec3 lightPosition = normalize(czm_a_viewerPositionWC); // czm_a_sunDirectionWC\n        float fLightAngle = dot(lightPosition, v3SamplePoint) / fHeight;\n        float fCameraAngle = dot(v3Ray, v3SamplePoint) / fHeight;\n        float fScatter = (fStartOffset + fDepth*(scale(fLightAngle) - scale(fCameraAngle)));\n        vec3 v3Attenuate = exp(-fScatter * (v3InvWavelength * fKr4PI + fKm4PI));\n        v3FrontColor += v3Attenuate * (fDepth * u_scaledLength);\n        v3SamplePoint += v3SampleRay;\n    }\n\n    // Finally, scale the Mie and Rayleigh colors and set up the varying variables for the pixel shader\n    v_mieColor = v3FrontColor * fKmESun;\n    v_rayleighColor = v3FrontColor * (v3InvWavelength * fKrESun);\n    v_toCamera = czm_a_viewerPositionWC - v3Pos;\n    gl_Position = czm_f_modelViewProjection * position;\n}\n",

    "SkyBoxFS": "\nuniform samplerCube u_cubeMap;\n\nvarying vec3 v_texCoord;\n\nvoid main()\n{\n    vec3 rgb = textureCube(u_cubeMap, normalize(v_texCoord)).rgb;\n    gl_FragColor = vec4(rgb, czm_a_morphTime);\n}\n",

    "SkyBoxVS": "\nattribute vec3 position;\n\nvarying vec3 v_texCoord;\n\nvoid main()\n{\n    vec3 p = czm_a_viewRotation * (czm_a_temeToPseudoFixed * (czm_f_entireFrustum.y * position));\n    gl_Position = czm_f_projection * vec4(p, 1.0);\n    v_texCoord = position.xyz;\n}\n",

    "SunFS": "\nuniform sampler2D u_texture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = texture2D(u_texture, v_textureCoordinates);\n}\n",

    "SunTextureFS": "\nuniform float u_glowLengthTS;\nuniform float u_radiusTS;\n\nvarying vec2 v_textureCoordinates;\n\nvec2 rotate(vec2 p, vec2 direction)\n{\n    return vec2(p.x * direction.x - p.y * direction.y, p.x * direction.y + p.y * direction.x);\n}\n\nvec4 addBurst(vec2 position, vec2 direction)\n{\n    vec2 rotatedPosition = rotate(position, direction) * vec2(25.0, 0.75);\n    float radius = length(rotatedPosition);\n    float burst = 1.0 - smoothstep(0.0, 0.55, radius);\n\n    return vec4(burst);\n}\n\nvoid main()\n{\n    vec2 position = v_textureCoordinates - vec2(0.5);\n    float radius = length(position);\n    float surface = step(radius, u_radiusTS);\n    vec4 color = vec4(1.0, 1.0, surface + 0.2, surface);\n\n    float glow = 1.0 - smoothstep(0.0, 0.55, radius);\n    color.ba += mix(vec2(0.0), vec2(1.0), glow) * 0.75;\n\n    vec4 burst = vec4(0.0);\n\n    // The following loop has been manually unrolled for speed, to\n    // avoid sin() and cos().\n    //\n    //for (float i = 0.4; i < 3.2; i += 1.047) {\n    //    vec2 direction = vec2(sin(i), cos(i));\n    //    burst += 0.4 * addBurst(position, direction);\n    //\n    //    direction = vec2(sin(i - 0.08), cos(i - 0.08));\n    //    burst += 0.3 * addBurst(position, direction);\n    //}\n\n    burst += 0.4 * addBurst(position, vec2(0.38942,  0.92106));  // angle == 0.4\n    burst += 0.4 * addBurst(position, vec2(0.99235,  0.12348));  // angle == 0.4 + 1.047\n    burst += 0.4 * addBurst(position, vec2(0.60327, -0.79754));  // angle == 0.4 + 1.047 * 2.0\n\n    burst += 0.3 * addBurst(position, vec2(0.31457,  0.94924));  // angle == 0.4 - 0.08\n    burst += 0.3 * addBurst(position, vec2(0.97931,  0.20239));  // angle == 0.4 + 1.047 - 0.08\n    burst += 0.3 * addBurst(position, vec2(0.66507, -0.74678));  // angle == 0.4 + 1.047 * 2.0 - 0.08\n\n    // End of manual loop unrolling.\n\n    color += clamp(burst, vec4(0.0), vec4(1.0)) * 0.15;\n    \n    gl_FragColor = clamp(color, vec4(0.0), vec4(1.0));\n}\n",

    "SunVS": "\nattribute vec2 direction;\n\nuniform float u_size;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main() \n{\n    vec4 position;\n    if (czm_a_morphTime == 1.0)\n    {\n        position = vec4(czm_sunPositionWC, 1.0);\n    }\n    else\n    {\n        position = vec4(czm_sunPositionColumbusView.zxy, 1.0);\n    }\n    \n    vec4 positionEC = czm_f_view * position;\n    vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n    \n    vec2 halfSize = vec2(u_size * 0.5);\n    halfSize *= ((direction * 2.0) - 1.0);\n    \n    gl_Position = czm_f_viewportOrthographic * vec4(positionWC.xy + halfSize, -positionWC.z, 1.0);\n    \n    v_textureCoordinates = direction;\n}\n",

    "ViewportQuadFS": "\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    czm_materialInput materialInput;\n    \n    materialInput.s = v_textureCoordinates.s;\n    materialInput.st = v_textureCoordinates;\n    materialInput.str = vec3(v_textureCoordinates, 0.0);\n    materialInput.normalEC = vec3(0.0, 0.0, -1.0);\n    \n    czm_material material = czm_getMaterial(materialInput);\n\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n}",

    "ViewportQuadVS": "\nattribute vec2 position;\nattribute vec2 textureCoordinates;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main() \n{\n    gl_Position = vec4(position, 0.0, 1.0);\n    v_textureCoordinates = textureCoordinates;\n}",

    "AdditiveBlendFS": "\nuniform sampler2D u_texture0;\nuniform sampler2D u_texture1;\n\nuniform vec2 u_center;\nuniform float u_radius;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    vec4 color0 = texture2D(u_texture0, v_textureCoordinates);\n    vec4 color1 = texture2D(u_texture1, v_textureCoordinates);\n    \n    float x = length(gl_FragCoord.xy - u_center) / u_radius;\n    float t = smoothstep(0.5, 0.8, x);\n    gl_FragColor = mix(color0 + color1, color0, t);\n}\n",

    "BrightPassFS": "\nuniform sampler2D u_texture;\n\nuniform float u_avgLuminance;\nuniform float u_threshold;\nuniform float u_offset;\n\nvarying vec2 v_textureCoordinates;\n\nfloat key(float avg)\n{\n    float guess = 1.5 - (1.5 / (avg * 0.1 + 1.0));\n    return max(0.0, guess) + 0.1;\n}\n\n// See section 9. 'The bright-pass filter' of Realtime HDR Rendering\n// http://www.cg.tuwien.ac.at/research/publications/2007/Luksch_2007_RHR/Luksch_2007_RHR-RealtimeHDR%20.pdf\n\nvoid main()\n{\n    vec4 color = texture2D(u_texture, v_textureCoordinates);\n    vec3 xyz = czm_RGBToXYZ(color.rgb);\n    float luminance = xyz.r;\n    \n    float scaledLum = key(u_avgLuminance) * luminance / u_avgLuminance;\n    float brightLum = max(scaledLum - u_threshold, 0.0);\n    float brightness = brightLum / (u_offset + brightLum);\n    \n    xyz.r = brightness;\n    gl_FragColor = vec4(czm_XYZToRGB(xyz), 1.0);\n}\n",

    "FXAAFS": "\n/**\n * @license\n * Copyright (c) 2011 NVIDIA Corporation. All rights reserved.\n *\n * TO  THE MAXIMUM  EXTENT PERMITTED  BY APPLICABLE  LAW, THIS SOFTWARE  IS PROVIDED\n * *AS IS*  AND NVIDIA AND  ITS SUPPLIERS DISCLAIM  ALL WARRANTIES,  EITHER  EXPRESS\n * OR IMPLIED, INCLUDING, BUT NOT LIMITED  TO, NONINFRINGEMENT,IMPLIED WARRANTIES OF\n * MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  IN NO EVENT SHALL  NVIDIA \n * OR ITS SUPPLIERS BE  LIABLE  FOR  ANY  DIRECT, SPECIAL,  INCIDENTAL,  INDIRECT,  OR  \n * CONSEQUENTIAL DAMAGES WHATSOEVER (INCLUDING, WITHOUT LIMITATION,  DAMAGES FOR LOSS \n * OF BUSINESS PROFITS, BUSINESS INTERRUPTION, LOSS OF BUSINESS INFORMATION, OR ANY \n * OTHER PECUNIARY LOSS) ARISING OUT OF THE  USE OF OR INABILITY  TO USE THIS SOFTWARE, \n * EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n */\n\n/*\nFXAA_PRESET - Choose compile-in knob preset 0-5.\n------------------------------------------------------------------------------\nFXAA_EDGE_THRESHOLD - The minimum amount of local contrast required \n                      to apply algorithm.\n                      1.0/3.0  - too little\n                      1.0/4.0  - good start\n                      1.0/8.0  - applies to more edges\n                      1.0/16.0 - overkill\n------------------------------------------------------------------------------\nFXAA_EDGE_THRESHOLD_MIN - Trims the algorithm from processing darks.\n                          Perf optimization.\n                          1.0/32.0 - visible limit (smaller isn't visible)\n                          1.0/16.0 - good compromise\n                          1.0/12.0 - upper limit (seeing artifacts)\n------------------------------------------------------------------------------\nFXAA_SEARCH_STEPS - Maximum number of search steps for end of span.\n------------------------------------------------------------------------------\nFXAA_SEARCH_THRESHOLD - Controls when to stop searching.\n                        1.0/4.0 - seems to be the best quality wise\n------------------------------------------------------------------------------\nFXAA_SUBPIX_TRIM - Controls sub-pixel aliasing removal.\n                   1.0/2.0 - low removal\n                   1.0/3.0 - medium removal\n                   1.0/4.0 - default removal\n                   1.0/8.0 - high removal\n                   0.0 - complete removal\n------------------------------------------------------------------------------\nFXAA_SUBPIX_CAP - Insures fine detail is not completely removed.\n                  This is important for the transition of sub-pixel detail,\n                  like fences and wires.\n                  3.0/4.0 - default (medium amount of filtering)\n                  7.0/8.0 - high amount of filtering\n                  1.0 - no capping of sub-pixel aliasing removal\n*/\n\n#ifndef FXAA_PRESET\n    #define FXAA_PRESET 3\n#endif\n#if (FXAA_PRESET == 3)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        16\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n#if (FXAA_PRESET == 4)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        24\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n#if (FXAA_PRESET == 5)\n    #define FXAA_EDGE_THRESHOLD      (1.0/8.0)\n    #define FXAA_EDGE_THRESHOLD_MIN  (1.0/24.0)\n    #define FXAA_SEARCH_STEPS        32\n    #define FXAA_SEARCH_THRESHOLD    (1.0/4.0)\n    #define FXAA_SUBPIX_CAP          (3.0/4.0)\n    #define FXAA_SUBPIX_TRIM         (1.0/4.0)\n#endif\n\n#define FXAA_SUBPIX_TRIM_SCALE (1.0/(1.0 - FXAA_SUBPIX_TRIM))\n\n// Return the luma, the estimation of luminance from rgb inputs.\n// This approximates luma using one FMA instruction,\n// skipping normalization and tossing out blue.\n// FxaaLuma() will range 0.0 to 2.963210702.\nfloat FxaaLuma(vec3 rgb) {\n    return rgb.y * (0.587/0.299) + rgb.x;\n}\n\nvec3 FxaaLerp3(vec3 a, vec3 b, float amountOfA) {\n    return (vec3(-amountOfA) * b) + ((a * vec3(amountOfA)) + b);\n}\n\nvec4 FxaaTexOff(sampler2D tex, vec2 pos, ivec2 off, vec2 rcpFrame) {\n    float x = pos.x + float(off.x) * rcpFrame.x;\n    float y = pos.y + float(off.y) * rcpFrame.y;\n    return texture2D(tex, vec2(x, y));\n}\n\n// pos is the output of FxaaVertexShader interpolated across screen.\n// xy -> actual texture position {0.0 to 1.0}\n// rcpFrame should be a uniform equal to  {1.0/frameWidth, 1.0/frameHeight}\nvec3 FxaaPixelShader(vec2 pos, sampler2D tex, vec2 rcpFrame)\n{\n    vec3 rgbN = FxaaTexOff(tex, pos.xy, ivec2( 0,-1), rcpFrame).xyz;\n    vec3 rgbW = FxaaTexOff(tex, pos.xy, ivec2(-1, 0), rcpFrame).xyz;\n    vec3 rgbM = FxaaTexOff(tex, pos.xy, ivec2( 0, 0), rcpFrame).xyz;\n    vec3 rgbE = FxaaTexOff(tex, pos.xy, ivec2( 1, 0), rcpFrame).xyz;\n    vec3 rgbS = FxaaTexOff(tex, pos.xy, ivec2( 0, 1), rcpFrame).xyz;\n    \n    float lumaN = FxaaLuma(rgbN);\n    float lumaW = FxaaLuma(rgbW);\n    float lumaM = FxaaLuma(rgbM);\n    float lumaE = FxaaLuma(rgbE);\n    float lumaS = FxaaLuma(rgbS);\n    float rangeMin = min(lumaM, min(min(lumaN, lumaW), min(lumaS, lumaE)));\n    float rangeMax = max(lumaM, max(max(lumaN, lumaW), max(lumaS, lumaE)));\n    \n    float range = rangeMax - rangeMin;\n    if(range < max(FXAA_EDGE_THRESHOLD_MIN, rangeMax * FXAA_EDGE_THRESHOLD))\n    {\n        return rgbM;\n    }\n    \n    vec3 rgbL = rgbN + rgbW + rgbM + rgbE + rgbS;\n    \n    float lumaL = (lumaN + lumaW + lumaE + lumaS) * 0.25;\n    float rangeL = abs(lumaL - lumaM);\n    float blendL = max(0.0, (rangeL / range) - FXAA_SUBPIX_TRIM) * FXAA_SUBPIX_TRIM_SCALE; \n    blendL = min(FXAA_SUBPIX_CAP, blendL);\n    \n    vec3 rgbNW = FxaaTexOff(tex, pos.xy, ivec2(-1,-1), rcpFrame).xyz;\n    vec3 rgbNE = FxaaTexOff(tex, pos.xy, ivec2( 1,-1), rcpFrame).xyz;\n    vec3 rgbSW = FxaaTexOff(tex, pos.xy, ivec2(-1, 1), rcpFrame).xyz;\n    vec3 rgbSE = FxaaTexOff(tex, pos.xy, ivec2( 1, 1), rcpFrame).xyz;\n    rgbL += (rgbNW + rgbNE + rgbSW + rgbSE);\n    rgbL *= vec3(1.0/9.0);\n    \n    float lumaNW = FxaaLuma(rgbNW);\n    float lumaNE = FxaaLuma(rgbNE);\n    float lumaSW = FxaaLuma(rgbSW);\n    float lumaSE = FxaaLuma(rgbSE);\n    \n    float edgeVert = \n        abs((0.25 * lumaNW) + (-0.5 * lumaN) + (0.25 * lumaNE)) +\n        abs((0.50 * lumaW ) + (-1.0 * lumaM) + (0.50 * lumaE )) +\n        abs((0.25 * lumaSW) + (-0.5 * lumaS) + (0.25 * lumaSE));\n    float edgeHorz = \n        abs((0.25 * lumaNW) + (-0.5 * lumaW) + (0.25 * lumaSW)) +\n        abs((0.50 * lumaN ) + (-1.0 * lumaM) + (0.50 * lumaS )) +\n        abs((0.25 * lumaNE) + (-0.5 * lumaE) + (0.25 * lumaSE));\n        \n    bool horzSpan = edgeHorz >= edgeVert;\n    float lengthSign = horzSpan ? -rcpFrame.y : -rcpFrame.x;\n    \n    if(!horzSpan)\n    {\n        lumaN = lumaW;\n        lumaS = lumaE;\n    }\n    \n    float gradientN = abs(lumaN - lumaM);\n    float gradientS = abs(lumaS - lumaM);\n    lumaN = (lumaN + lumaM) * 0.5;\n    lumaS = (lumaS + lumaM) * 0.5;\n    \n    if (gradientN < gradientS)\n    {\n        lumaN = lumaS;\n        lumaN = lumaS;\n        gradientN = gradientS;\n        lengthSign *= -1.0;\n    }\n    \n    vec2 posN;\n    posN.x = pos.x + (horzSpan ? 0.0 : lengthSign * 0.5);\n    posN.y = pos.y + (horzSpan ? lengthSign * 0.5 : 0.0);\n    \n    gradientN *= FXAA_SEARCH_THRESHOLD;\n    \n    vec2 posP = posN;\n    vec2 offNP = horzSpan ? vec2(rcpFrame.x, 0.0) : vec2(0.0, rcpFrame.y); \n    float lumaEndN = lumaN;\n    float lumaEndP = lumaN;\n    bool doneN = false;\n    bool doneP = false;\n    posN += offNP * vec2(-1.0, -1.0);\n    posP += offNP * vec2( 1.0,  1.0);\n    \n    for(int i = 0; i < FXAA_SEARCH_STEPS; i++) {\n        if(!doneN)\n        {\n            lumaEndN = FxaaLuma(texture2D(tex, posN.xy).xyz);\n        }\n        if(!doneP)\n        {\n            lumaEndP = FxaaLuma(texture2D(tex, posP.xy).xyz);\n        }\n        \n        doneN = doneN || (abs(lumaEndN - lumaN) >= gradientN);\n        doneP = doneP || (abs(lumaEndP - lumaN) >= gradientN);\n        \n        if(doneN && doneP)\n        {\n            break;\n        }\n        if(!doneN)\n        {\n            posN -= offNP;\n        }\n        if(!doneP)\n        {\n            posP += offNP;\n        }\n    }\n    \n    float dstN = horzSpan ? pos.x - posN.x : pos.y - posN.y;\n    float dstP = horzSpan ? posP.x - pos.x : posP.y - pos.y;\n    bool directionN = dstN < dstP;\n    lumaEndN = directionN ? lumaEndN : lumaEndP;\n    \n    if(((lumaM - lumaN) < 0.0) == ((lumaEndN - lumaN) < 0.0))\n    {\n        lengthSign = 0.0;\n    }\n \n\n    float spanLength = (dstP + dstN);\n    dstN = directionN ? dstN : dstP;\n    float subPixelOffset = (0.5 + (dstN * (-1.0/spanLength))) * lengthSign;\n    vec3 rgbF = texture2D(tex, vec2(\n        pos.x + (horzSpan ? 0.0 : subPixelOffset),\n        pos.y + (horzSpan ? subPixelOffset : 0.0))).xyz;\n    return FxaaLerp3(rgbL, rgbF, blendL); \n}\n\nuniform sampler2D u_texture;\nuniform vec2 u_step;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = vec4(FxaaPixelShader(v_textureCoordinates, u_texture, u_step), 1.0);\n}\n",

    "GaussianBlur1DFS": "\n#define SAMPLES 8\n\nuniform float delta;\nuniform float sigma;\nuniform float direction; // 0.0 for x direction, 1.0 for y direction\n\nuniform sampler2D u_texture;\nuniform vec2 u_step;\n\nvarying vec2 v_textureCoordinates;\n\n//  Incremental Computation of the Gaussian:\n//  http://http.developer.nvidia.com/GPUGems3/gpugems3_ch40.html\n\nvoid main()\n{\n    vec2 st = v_textureCoordinates;\n    \n    vec2 dir = vec2(1.0 - direction, direction);\n    \n    vec3 g;\n    g.x = 1.0 / (sqrt(czm_twoPi) * sigma);\n    g.y = exp((-0.5 * delta * delta) / (sigma * sigma));\n    g.z = g.y * g.y;\n    \n    vec4 result = texture2D(u_texture, st) * g.x;\n    for (int i = 1; i < SAMPLES; ++i)\n    {\n        g.xy *= g.yz;\n        \n        vec2 offset = float(i) * dir * u_step;\n        result += texture2D(u_texture, st - offset) * g.x;\n        result += texture2D(u_texture, st + offset) * g.x;\n    }\n    \n    gl_FragColor = result;\n}\n",

    "PassThroughFS": "\nuniform sampler2D u_texture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main() \n{\n    gl_FragColor = texture2D(u_texture, v_textureCoordinates);\n}\n",


]

let Builtins: [String: String] = [
    "czm_degreesPerRadian": "\n/**\n * A built-in GLSL floating-point constant for converting radians to degrees.\n *\n * @alias czm_degreesPerRadian\n * @glslConstant\n *\n * @see CesiumMath.DEGREES_PER_RADIAN\n *\n * @example\n * // GLSL declaration\n * const float czm_degreesPerRadian = ...;\n *\n * // Example\n * float deg = czm_degreesPerRadian * rad;\n */\nconst float czm_degreesPerRadian = 57.29577951308232;",

    "czm_depthRange": "\n/**\n * A built-in GLSL vec2 constant for defining the depth range.\n * This is a workaround to a bug where IE11 does not implement gl_DepthRange.\n *\n * @alias czm_depthRange\n * @glslConstant\n *\n * @example\n * // GLSL declaration\n * float depthRangeNear = czm_depthRange.near;\n * float depthRangeFar = czm_depthRange.far;\n *\n */\nconst czm_depthRangeStruct czm_depthRange = czm_depthRangeStruct(0.0, 1.0);",

    "czm_epsilon1": "\n/**\n * 0.1\n *\n * @name czm_epsilon1\n * @glslConstant\n */\nconst float czm_epsilon1 = 0.1;",

    "czm_epsilon2": "\n/**\n * 0.01\n *\n * @name czm_epsilon2\n * @glslConstant\n */\nconst float czm_epsilon2 = 0.01;",

    "czm_epsilon3": "\n/**\n * 0.001\n *\n * @name czm_epsilon3\n * @glslConstant\n */\nconst float czm_epsilon3 = 0.001;",

    "czm_epsilon4": "\n/**\n * 0.0001\n *\n * @name czm_epsilon4\n * @glslConstant\n */\nconst float czm_epsilon4 = 0.0001;",

    "czm_epsilon5": "\n/**\n * 0.00001\n *\n * @name czm_epsilon5\n * @glslConstant\n */\nconst float czm_epsilon5 = 0.00001;",

    "czm_epsilon6": "\n/**\n * 0.000001\n *\n * @name czm_epsilon6\n * @glslConstant\n */\nconst float czm_epsilon6 = 0.000001;",

    "czm_epsilon7": "\n/**\n * 0.0000001\n *\n * @name czm_epsilon7\n * @glslConstant\n */\nconst float czm_epsilon7 = 0.0000001;",

    "czm_infinity": "\n/**\n * DOC_TBA\n *\n * @name czm_infinity\n * @glslConstant\n */\nconst float czm_infinity = 5906376272000.0;  // Distance from the Sun to Pluto in meters.  TODO: What is best given lowp, mediump, and highp?",

    "czm_oneOverPi": "\n/**\n * A built-in GLSL floating-point constant for <code>1/pi</code>.\n *\n * @alias czm_oneOverPi\n * @glslConstant\n *\n * @see CesiumMath.ONE_OVER_PI\n *\n * @example\n * // GLSL declaration\n * const float czm_oneOverPi = ...;\n *\n * // Example\n * float pi = 1.0 / czm_oneOverPi;\n */\nconst float czm_oneOverPi = 0.3183098861837907;",

    "czm_oneOverTwoPi": "\n/**\n * A built-in GLSL floating-point constant for <code>1/2pi</code>.\n *\n * @alias czm_oneOverTwoPi\n * @glslConstant\n *\n * @see CesiumMath.ONE_OVER_TWO_PI\n *\n * @example\n * // GLSL declaration\n * const float czm_oneOverTwoPi = ...;\n *\n * // Example\n * float pi = 2.0 * czm_oneOverTwoPi;\n */\nconst float czm_oneOverTwoPi = 0.15915494309189535;",

    "czm_passCompute": "/**\n * The automatic GLSL constant for {@link Pass#COMPUTE}\n *\n * @name czm_passCompute\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passCompute = 1.0;",

    "czm_passEnvironment": "/**\n * The automatic GLSL constant for {@link Pass#ENVIRONMENT}\n *\n * @name czm_passEnvironment\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passEnvironment = 0.0;",

    "czm_passGlobe": "/**\n * The automatic GLSL constant for {@link Pass#GLOBE}\n *\n * @name czm_passGlobe\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passGlobe = 2.0;",

    "czm_passGround": "/**\n * The automatic GLSL constant for {@link Pass#GROUND}\n *\n * @name czm_passGround\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passGround = 3.0;",

    "czm_passOpaque": "/**\n * The automatic GLSL constant for {@link Pass#OPAQUE}\n *\n * @name czm_passOpaque\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passOpaque = 4.0;",

    "czm_passOverlay": "/**\n * The automatic GLSL constant for {@link Pass#OVERLAY}\n *\n * @name czm_passOverlay\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passOverlay = 6.0;",

    "czm_passTranslucent": "/**\n * The automatic GLSL constant for {@link Pass#TRANSLUCENT}\n *\n * @name czm_passTranslucent\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passTranslucent = 5.0;",

    "czm_pi": "\n/**\n * A built-in GLSL floating-point constant for <code>Math.PI</code>.\n *\n * @alias czm_pi\n * @glslConstant\n *\n * @see CesiumMath.PI\n *\n * @example\n * // GLSL declaration\n * const float czm_pi = ...;\n *\n * // Example\n * float twoPi = 2.0 * czm_pi;\n */\nconst float czm_pi = 3.141592653589793;",

    "czm_piOverFour": "\n/**\n * A built-in GLSL floating-point constant for <code>pi/4</code>.\n *\n * @alias czm_piOverFour\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_FOUR\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverFour = ...;\n *\n * // Example\n * float pi = 4.0 * czm_piOverFour;\n */\nconst float czm_piOverFour = 0.7853981633974483;",

    "czm_piOverSix": "\n/**\n * A built-in GLSL floating-point constant for <code>pi/6</code>.\n *\n * @alias czm_piOverSix\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_SIX\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverSix = ...;\n *\n * // Example\n * float pi = 6.0 * czm_piOverSix;\n */\nconst float czm_piOverSix = 0.5235987755982988;",

    "czm_piOverThree": "\n/**\n * A built-in GLSL floating-point constant for <code>pi/3</code>.\n *\n * @alias czm_piOverThree\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_THREE\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverThree = ...;\n *\n * // Example\n * float pi = 3.0 * czm_piOverThree;\n */\nconst float czm_piOverThree = 1.0471975511965976;",

    "czm_piOverTwo": "\n/**\n * A built-in GLSL floating-point constant for <code>pi/2</code>.\n *\n * @alias czm_piOverTwo\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_TWO\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverTwo = ...;\n *\n * // Example\n * float pi = 2.0 * czm_piOverTwo;\n */\nconst float czm_piOverTwo = 1.5707963267948966;",

    "czm_radiansPerDegree": "\n/**\n * A built-in GLSL floating-point constant for converting degrees to radians.\n *\n * @alias czm_radiansPerDegree\n * @glslConstant\n *\n * @see CesiumMath.RADIANS_PER_DEGREE\n *\n * @example\n * // GLSL declaration\n * const float czm_radiansPerDegree = ...;\n *\n * // Example\n * float rad = czm_radiansPerDegree * deg;\n */\nconst float czm_radiansPerDegree = 0.017453292519943295;",

    "czm_sceneMode2D": "\n/**\n * The constant identifier for the 2D {@link SceneMode}\n *\n * @name czm_sceneMode2D\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneModeColumbusView\n * @see czm_sceneMode3D\n * @see czm_sceneModeMorphing\n */\nconst float czm_sceneMode2D = 2.0;",

    "czm_sceneMode3D": "\n/**\n * The constant identifier for the 3D {@link SceneMode}\n *\n * @name czm_sceneMode3D\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneMode2D\n * @see czm_sceneModeColumbusView\n * @see czm_sceneModeMorphing\n */\nconst float czm_sceneMode3D = 3.0;",

    "czm_sceneModeColumbusView": "\n/**\n * The constant identifier for the Columbus View {@link SceneMode}\n *\n * @name czm_sceneModeColumbusView\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneMode2D\n * @see czm_sceneMode3D\n * @see czm_sceneModeMorphing\n */\nconst float czm_sceneModeColumbusView = 1.0;",

    "czm_sceneModeMorphing": "\n/**\n * The constant identifier for the Morphing {@link SceneMode}\n *\n * @name czm_sceneModeMorphing\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneMode2D\n * @see czm_sceneModeColumbusView\n * @see czm_sceneMode3D\n */\nconst float czm_sceneModeMorphing = 0.0;",

    "czm_solarRadius": "\n/**\n * A built-in GLSL floating-point constant for one solar radius.\n *\n * @alias czm_solarRadius\n * @glslConstant\n *\n * @see CesiumMath.SOLAR_RADIUS\n *\n * @example\n * // GLSL declaration\n * const float czm_solarRadius = ...;\n */\nconst float czm_solarRadius = 695500000.0;",

    "czm_threePiOver2": "\n/**\n * A built-in GLSL floating-point constant for <code>3pi/2</code>.\n *\n * @alias czm_threePiOver2\n * @glslConstant\n *\n * @see CesiumMath.THREE_PI_OVER_TWO\n *\n * @example\n * // GLSL declaration\n * const float czm_threePiOver2 = ...;\n *\n * // Example\n * float pi = (2.0 / 3.0) * czm_threePiOver2;\n */\nconst float czm_threePiOver2 = 4.71238898038469;",

    "czm_twoPi": "\n/**\n * A built-in GLSL floating-point constant for <code>2pi</code>.\n *\n * @alias czm_twoPi\n * @glslConstant\n *\n * @see CesiumMath.TWO_PI\n *\n * @example\n * // GLSL declaration\n * const float czm_twoPi = ...;\n *\n * // Example\n * float pi = czm_twoPi / 2.0;\n */\nconst float czm_twoPi = 6.283185307179586;",

    "czm_webMercatorMaxLatitude": "\n/**\n * The maximum latitude, in radians, both North and South, supported by a Web Mercator\n * (EPSG:3857) projection.  Technically, the Mercator projection is defined\n * for any latitude up to (but not including) 90 degrees, but it makes sense\n * to cut it off sooner because it grows exponentially with increasing latitude.\n * The logic behind this particular cutoff value, which is the one used by\n * Google Maps, Bing Maps, and Esri, is that it makes the projection\n * square.  That is, the rectangle is equal in the X and Y directions.\n *\n * The constant value is computed as follows:\n *   czm_pi * 0.5 - (2.0 * atan(exp(-czm_pi)))\n *\n * @name czm_webMercatorMaxLatitude\n * @glslConstant\n */\nconst float czm_webMercatorMaxLatitude = 1.4844222297453324;",

    "czm_alphaWeight": "\n/**\n * @private\n */\nfloat czm_alphaWeight(float a)\n{\n    float z;\n    if (czm_sceneMode != czm_sceneMode2D)\n    {\n        float x = 2.0 * (gl_FragCoord.x - czm_f_viewport.x) / czm_f_viewport.z - 1.0;\n        float y = 2.0 * (gl_FragCoord.y - czm_f_viewport.y) / czm_f_viewport.w - 1.0;\n        z = (gl_FragCoord.z - czm_f_viewportTransformation[3][2]) / czm_f_viewportTransformation[2][2];\n        vec4 q = vec4(x, y, z, 0.0);\n        q /= gl_FragCoord.w;\n        z = (czm_inverseProjectionOIT * q).z;\n    }\n    else\n    {\n        z = gl_FragCoord.z * (czm_currentFrustum.y - czm_currentFrustum.x) + czm_currentFrustum.x;\n    }\n    \n    // See Weighted Blended Order-Independent Transparency for examples of different weighting functions:\n    // http://jcgt.org/published/0002/02/09/\n    return pow(a + 0.01, 4.0) + max(1e-2, min(3.0 * 1e3, 100.0 / (1e-5 + pow(abs(z) / 10.0, 3.0) + pow(abs(z) / 200.0, 6.0))));\n}",

    "czm_antialias": "\n/**\n * Procedural anti-aliasing by blurring two colors that meet at a sharp edge.\n *\n * @name czm_antialias\n * @glslFunction\n *\n * @param {vec4} color1 The color on one side of the edge.\n * @param {vec4} color2 The color on the other side of the edge.\n * @param {vec4} currentcolor The current color, either <code>color1</code> or <code>color2</code>.\n * @param {float} dist The distance to the edge in texture coordinates.\n * @param {float} [fuzzFactor=0.1] Controls the blurriness between the two colors.\n * @returns {vec4} The anti-aliased color.\n *\n * @example\n * // GLSL declarations\n * vec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist, float fuzzFactor);\n * vec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist);\n *\n * // get the color for a material that has a sharp edge at the line y = 0.5 in texture space\n * float dist = abs(textureCoordinates.t - 0.5);\n * vec4 currentColor = mix(bottomColor, topColor, step(0.5, textureCoordinates.t));\n * vec4 color = czm_antialias(bottomColor, topColor, currentColor, dist, 0.1);\n */\nvec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist, float fuzzFactor)\n{\n    float val1 = clamp(dist / fuzzFactor, 0.0, 1.0);\n    float val2 = clamp((dist - 0.5) / fuzzFactor, 0.0, 1.0);\n    val1 = val1 * (1.0 - val2);\n    val1 = val1 * val1 * (3.0 - (2.0 * val1));\n    val1 = pow(val1, 0.5); //makes the transition nicer\n    \n    vec4 midColor = (color1 + color2) * 0.5;\n    return mix(midColor, currentColor, val1);\n}\n\nvec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist)\n{\n    return czm_antialias(color1, color2, currentColor, dist, 0.1);\n}\n",

    "czm_columbusViewMorph": "\n/**\n * DOC_TBA\n *\n * @name czm_columbusViewMorph\n * @glslFunction\n */\nvec4 czm_columbusViewMorph(vec4 position2D, vec4 position3D, float time)\n{\n    // Just linear for now.\n    vec3 p = mix(position2D.xyz, position3D.xyz, time);\n    return vec4(p, 1.0);\n}\n",

    "czm_computePosition": "\n/**\n * Returns a position in model coordinates relative to eye taking into\n * account the current scene mode: 3D, 2D, or Columbus view.\n * <p>\n * This uses standard position attributes, <code>position3DHigh</code>, \n * <code>position3DLow</code>, <code>position2DHigh</code>, and <code>position2DLow</code>, \n * and should be used when writing a vertex shader for an {@link Appearance}.\n * </p>\n *\n * @name czm_computePosition\n * @glslFunction\n *\n * @returns {vec4} The position relative to eye.\n *\n * @example\n * vec4 p = czm_computePosition();\n * v_positionEC = (czm_modelViewRelativeToEye * p).xyz;\n * gl_Position = czm_modelViewProjectionRelativeToEye * p;\n *\n * @see czm_translateRelativeToEye\n */\nvec4 czm_computePosition();\n",

    "czm_cosineAndSine": "\n/**\n * @private\n */\nvec2 cordic(float angle)\n{\n// Scale the vector by the appropriate factor for the 24 iterations to follow.\n    vec2 vector = vec2(6.0725293500888267e-1, 0.0);\n// Iteration 1\n    float sense = (angle < 0.0) ? -1.0 : 1.0;\n //   float factor = sense * 1.0;  // 2^-0\n    mat2 rotation = mat2(1.0, sense, -sense, 1.0);\n    vector = rotation * vector;\n    angle -= sense * 7.8539816339744828e-1;  // atan(2^-0)\n// Iteration 2\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    float factor = sense * 5.0e-1;  // 2^-1\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 4.6364760900080609e-1;  // atan(2^-1)\n// Iteration 3\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 2.5e-1;  // 2^-2\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 2.4497866312686414e-1;  // atan(2^-2)\n// Iteration 4\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.25e-1;  // 2^-3\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.2435499454676144e-1;  // atan(2^-3)\n// Iteration 5\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 6.25e-2;  // 2^-4\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 6.2418809995957350e-2;  // atan(2^-4)\n// Iteration 6\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.125e-2;  // 2^-5\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.1239833430268277e-2;  // atan(2^-5)\n// Iteration 7\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.5625e-2;  // 2^-6\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.5623728620476831e-2;  // atan(2^-6)\n// Iteration 8\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 7.8125e-3;  // 2^-7\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 7.8123410601011111e-3;  // atan(2^-7)\n// Iteration 9\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.90625e-3;  // 2^-8\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.9062301319669718e-3;  // atan(2^-8)\n// Iteration 10\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.953125e-3;  // 2^-9\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.9531225164788188e-3;  // atan(2^-9)\n// Iteration 11\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 9.765625e-4;  // 2^-10\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 9.7656218955931946e-4;  // atan(2^-10)\n// Iteration 12\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 4.8828125e-4;  // 2^-11\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 4.8828121119489829e-4;  // atan(2^-11)\n// Iteration 13\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 2.44140625e-4;  // 2^-12\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 2.4414062014936177e-4;  // atan(2^-12)\n// Iteration 14\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.220703125e-4;  // 2^-13\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.2207031189367021e-4;  // atan(2^-13)\n// Iteration 15\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 6.103515625e-5;  // 2^-14\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 6.1035156174208773e-5;  // atan(2^-14)\n// Iteration 16\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.0517578125e-5;  // 2^-15\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.0517578115526096e-5;  // atan(2^-15)\n// Iteration 17\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.52587890625e-5;  // 2^-16\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.5258789061315762e-5;  // atan(2^-16)\n// Iteration 18\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 7.62939453125e-6;  // 2^-17\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 7.6293945311019700e-6;  // atan(2^-17)\n// Iteration 19\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.814697265625e-6;  // 2^-18\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.8146972656064961e-6;  // atan(2^-18)\n// Iteration 20\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.9073486328125e-6;  // 2^-19\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.9073486328101870e-6;  // atan(2^-19)\n// Iteration 21\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 9.5367431640625e-7;  // 2^-20\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 9.5367431640596084e-7;  // atan(2^-20)\n// Iteration 22\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 4.76837158203125e-7;  // 2^-21\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 4.7683715820308884e-7;  // atan(2^-21)\n// Iteration 23\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 2.384185791015625e-7;  // 2^-22\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 2.3841857910155797e-7;  // atan(2^-22)\n// Iteration 24\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.1920928955078125e-7;  // 2^-23\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n//    angle -= sense * 1.1920928955078068e-7;  // atan(2^-23)\n\n    return vector;\n}\n\n/**\n * Computes the cosine and sine of the provided angle using the CORDIC algorithm.\n *\n * @name czm_cosineAndSine\n * @glslFunction\n *\n * @param {float} angle The angle in radians.\n *\n * @returns {vec2} The resulting cosine of the angle (as the x coordinate) and sine of the angle (as the y coordinate).\n *\n * @example\n * vec2 v = czm_cosineAndSine(czm_piOverSix);\n * float cosine = v.x;\n * float sine = v.y;\n */\nvec2 czm_cosineAndSine(float angle)\n{\n    if (angle < -czm_piOverTwo || angle > czm_piOverTwo)\n    {\n        if (angle < 0.0)\n        {\n            return -cordic(angle + czm_pi);\n        }\n        else\n        {\n            return -cordic(angle - czm_pi);\n        }\n    }\n    else\n    {\n        return cordic(angle);\n    }\n}",

    "czm_decompressTextureCoordinates": "\n/**\n * Decompresses texture coordinates that were packed into a single float.\n *\n * @name czm_decompressTextureCoordinates\n * @glslFunction\n *\n * @param {float} encoded The compressed texture coordinates.\n * @returns {vec2} The decompressed texture coordinates.\n */\n vec2 czm_decompressTextureCoordinates(float encoded)\n {\n    float temp = encoded / 4096.0;\n    float stx = floor(temp) / 4096.0;\n    float sty = temp - floor(temp);\n    return vec2(stx, sty);\n }\n",

    "czm_eastNorthUpToEyeCoordinates": "\n/**\n * Computes a 3x3 rotation matrix that transforms vectors from an ellipsoid's east-north-up coordinate system \n * to eye coordinates.  In east-north-up coordinates, x points east, y points north, and z points along the \n * surface normal.  East-north-up can be used as an ellipsoid's tangent space for operations such as bump mapping.\n * <br /><br />\n * The ellipsoid is assumed to be centered at the model coordinate's origin.\n *\n * @name czm_eastNorthUpToEyeCoordinates\n * @glslFunction\n *\n * @param {vec3} positionMC The position on the ellipsoid in model coordinates.\n * @param {vec3} normalEC The normalized ellipsoid surface normal, at <code>positionMC</code>, in eye coordinates.\n *\n * @returns {mat3} A 3x3 rotation matrix that transforms vectors from the east-north-up coordinate system to eye coordinates.\n *\n * @example\n * // Transform a vector defined in the east-north-up coordinate \n * // system, (0, 0, 1) which is the surface normal, to eye \n * // coordinates.\n * mat3 m = czm_eastNorthUpToEyeCoordinates(positionMC, normalEC);\n * vec3 normalEC = m * vec3(0.0, 0.0, 1.0);\n */\nmat3 czm_eastNorthUpToEyeCoordinates(vec3 positionMC, vec3 normalEC)\n{\n    vec3 tangentMC = normalize(vec3(-positionMC.y, positionMC.x, 0.0));  // normalized surface tangent in model coordinates\n    vec3 tangentEC = normalize(czm_f_normal3D * tangentMC);                // normalized surface tangent in eye coordiantes\n    vec3 bitangentEC = normalize(cross(normalEC, tangentEC));            // normalized surface bitangent in eye coordinates\n\n    return mat3(\n        tangentEC.x,   tangentEC.y,   tangentEC.z,\n        bitangentEC.x, bitangentEC.y, bitangentEC.z,\n        normalEC.x,    normalEC.y,    normalEC.z);\n}\n",

    "czm_ellipsoidContainsPoint": "\n/**\n * DOC_TBA\n *\n * @name czm_ellipsoidContainsPoint\n * @glslFunction\n *\n */\nbool czm_ellipsoidContainsPoint(czm_ellipsoid ellipsoid, vec3 point)\n{\n    vec3 scaled = ellipsoid.inverseRadii * (czm_f_inverseModelView * vec4(point, 1.0)).xyz;\n    return (dot(scaled, scaled) <= 1.0);\n}\n",

    "czm_ellipsoidNew": "\n/**\n * DOC_TBA\n *\n * @name czm_ellipsoidNew\n * @glslFunction\n *\n */\nczm_ellipsoid czm_ellipsoidNew(vec3 center, vec3 radii)\n{\n    vec3 inverseRadii = vec3(1.0 / radii.x, 1.0 / radii.y, 1.0 / radii.z);\n    vec3 inverseRadiiSquared = inverseRadii * inverseRadii;\n    czm_ellipsoid temp = czm_ellipsoid(center, radii, inverseRadii, inverseRadiiSquared);\n    return temp;\n}\n",

    "czm_ellipsoidWgs84TextureCoordinates": "\n/**\n * DOC_TBA\n *\n * @name czm_ellipsoidWgs84TextureCoordinates\n * @glslFunction\n */\nvec2 czm_ellipsoidWgs84TextureCoordinates(vec3 normal)\n{\n    return vec2(atan(normal.y, normal.x) * czm_oneOverTwoPi + 0.5, asin(normal.z) * czm_oneOverPi + 0.5);\n}\n",

    "czm_equalsEpsilon": "\n/**\n * Compares <code>left</code> and <code>right</code> componentwise. Returns <code>true</code>\n * if they are within <code>epsilon</code> and <code>false</code> otherwise. The inputs\n * <code>left</code> and <code>right</code> can be <code>float</code>s, <code>vec2</code>s,\n * <code>vec3</code>s, or <code>vec4</code>s.\n *\n * @name czm_equalsEpsilon\n * @glslFunction\n *\n * @param {} left The first vector.\n * @param {} right The second vector.\n * @param {float} epsilon The epsilon to use for equality testing.\n * @returns {bool} <code>true</code> if the components are within <code>epsilon</code> and <code>false</code> otherwise.\n *\n * @example\n * // GLSL declarations\n * bool czm_equalsEpsilon(float left, float right, float epsilon);\n * bool czm_equalsEpsilon(vec2 left, vec2 right, float epsilon);\n * bool czm_equalsEpsilon(vec3 left, vec3 right, float epsilon);\n * bool czm_equalsEpsilon(vec4 left, vec4 right, float epsilon);\n */\nbool czm_equalsEpsilon(vec4 left, vec4 right, float epsilon) {\n    return all(lessThanEqual(abs(left - right), vec4(epsilon)));\n}\n\nbool czm_equalsEpsilon(vec3 left, vec3 right, float epsilon) {\n    return all(lessThanEqual(abs(left - right), vec3(epsilon)));\n}\n\nbool czm_equalsEpsilon(vec2 left, vec2 right, float epsilon) {\n    return all(lessThanEqual(abs(left - right), vec2(epsilon)));\n}\n\nbool czm_equalsEpsilon(float left, float right, float epsilon) {\n    return (abs(left - right) <= epsilon);\n}\n",

    "czm_eyeOffset": "\n/**\n * DOC_TBA\n *\n * @name czm_eyeOffset\n * @glslFunction\n *\n * @param {vec4} positionEC DOC_TBA.\n * @param {vec3} eyeOffset DOC_TBA.\n *\n * @returns {vec4} DOC_TBA.\n */\nvec4 czm_eyeOffset(vec4 positionEC, vec3 eyeOffset)\n{\n    // This equation is approximate in x and y.\n    vec4 p = positionEC;\n    vec4 zEyeOffset = normalize(p) * eyeOffset.z;\n    p.xy += eyeOffset.xy + zEyeOffset.xy;\n    p.z += zEyeOffset.z;\n    return p;\n}\n",

    "czm_eyeToWindowCoordinates": "\n/**\n * Transforms a position from eye to window coordinates.  The transformation\n * from eye to clip coordinates is done using {@link czm_f_projection}.\n * The transform from normalized device coordinates to window coordinates is\n * done using {@link czm_f_viewportTransformation}, which assumes a depth range\n * of <code>near = 0</code> and <code>far = 1</code>.\n * <br /><br />\n * This transform is useful when there is a need to manipulate window coordinates\n * in a vertex shader as done by {@link BillboardCollection}.\n *\n * @name czm_eyeToWindowCoordinates\n * @glslFunction\n *\n * @param {vec4} position The position in eye coordinates to transform.\n *\n * @returns {vec4} The transformed position in window coordinates.\n *\n * @see czm_modelToWindowCoordinates\n * @see czm_f_projection\n * @see czm_f_viewportTransformation\n * @see BillboardCollection\n *\n * @example\n * vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n */\nvec4 czm_eyeToWindowCoordinates(vec4 positionEC)\n{\n    vec4 q = czm_f_projection * positionEC;                        // clip coordinates\n    q.xyz /= q.w;                                                // normalized device coordinates\n    q.xyz = (czm_f_viewportTransformation * vec4(q.xyz, 1.0)).xyz; // window coordinates\n    return q;\n}\n",

    "czm_fog": "\n/**\n * Gets the color with fog at a distance from the camera.\n * \n * @name czm_fog\n * @glslFunction\n * \n * @param {float} distanceToCamera The distance to the camera in meters.\n * @param {vec3} color The original color.\n * @param {vec3} fogColor The color of the fog.\n *\n * @returns {vec3} The color adjusted for fog at the distance from the camera.\n */\nvec3 czm_fog(float distanceToCamera, vec3 color, vec3 fogColor)\n{\n    float scalar = distanceToCamera * czm_a_fogDensity;\n    float fog = 1.0 - exp(-(scalar * scalar));\n    \n    return mix(color, fogColor, fog);\n}\n",

    "czm_geodeticSurfaceNormal": "\n/**\n * DOC_TBA\n *\n * @name czm_geodeticSurfaceNormal\n * @glslFunction\n *\n * @param {vec3} positionOnEllipsoid DOC_TBA\n * @param {vec3} ellipsoidCenter DOC_TBA\n * @param {vec3} oneOverEllipsoidRadiiSquared DOC_TBA\n * \n * @returns {vec3} DOC_TBA.\n */\nvec3 czm_geodeticSurfaceNormal(vec3 positionOnEllipsoid, vec3 ellipsoidCenter, vec3 oneOverEllipsoidRadiiSquared)\n{\n    return normalize((positionOnEllipsoid - ellipsoidCenter) * oneOverEllipsoidRadiiSquared);\n}\n",

    "czm_getDefaultMaterial": "\n/**\n * An czm_material with default values. Every material's czm_getMaterial\n * should use this default material as a base for the material it returns.\n * The default normal value is given by materialInput.normalEC.\n *\n * @name czm_getDefaultMaterial\n * @glslFunction \n *\n * @param {czm_materialInput} input The input used to construct the default material.\n * \n * @returns {czm_material} The default material.\n *\n * @see czm_materialInput\n * @see czm_material\n * @see czm_getMaterial\n */\nczm_material czm_getDefaultMaterial(czm_materialInput materialInput)\n{\n    czm_material material;\n    material.diffuse = vec3(0.0);\n    material.specular = 0.0;\n    material.shininess = 1.0;\n    material.normal = materialInput.normalEC;\n    material.emission = vec3(0.0);\n    material.alpha = 1.0;\n    return material;\n}\n",

    "czm_getLambertDiffuse": "\n/**\n * Calculates the intensity of diffusely reflected light.\n *\n * @name czm_getLambertDiffuse\n * @glslFunction\n *\n * @param {vec3} lightDirectionEC Unit vector pointing to the light source in eye coordinates.\n * @param {vec3} normalEC The surface normal in eye coordinates.\n *\n * @returns {float} The intensity of the diffuse reflection.\n *\n * @see czm_phong\n *\n * @example\n * float diffuseIntensity = czm_getLambertDiffuse(lightDirectionEC, normalEC);\n * float specularIntensity = czm_getSpecular(lightDirectionEC, toEyeEC, normalEC, 200);\n * vec3 color = (diffuseColor * diffuseIntensity) + (specularColor * specularIntensity);\n */\nfloat czm_getLambertDiffuse(vec3 lightDirectionEC, vec3 normalEC)\n{\n    return max(dot(lightDirectionEC, normalEC), 0.0);\n}",

    "czm_getSpecular": "\n/**\n * Calculates the specular intensity of reflected light.\n *\n * @name czm_getSpecular\n * @glslFunction\n *\n * @param {vec3} lightDirectionEC Unit vector pointing to the light source in eye coordinates.\n * @param {vec3} toEyeEC Unit vector pointing to the eye position in eye coordinates.\n * @param {vec3} normalEC The surface normal in eye coordinates.\n * @param {float} shininess The sharpness of the specular reflection.  Higher values create a smaller, more focused specular highlight.\n *\n * @returns {float} The intensity of the specular highlight.\n *\n * @see czm_phong\n *\n * @example\n * float diffuseIntensity = czm_getLambertDiffuse(lightDirectionEC, normalEC);\n * float specularIntensity = czm_getSpecular(lightDirectionEC, toEyeEC, normalEC, 200);\n * vec3 color = (diffuseColor * diffuseIntensity) + (specularColor * specularIntensity);\n */\nfloat czm_getSpecular(vec3 lightDirectionEC, vec3 toEyeEC, vec3 normalEC, float shininess)\n{\n    vec3 toReflectedLight = reflect(-lightDirectionEC, normalEC);\n    float specular = max(dot(toReflectedLight, toEyeEC), 0.0);\n    return pow(specular, shininess);\n}",

    "czm_getWaterNoise": "\n/**\n * @private\n */\nvec4 czm_getWaterNoise(sampler2D normalMap, vec2 uv, float time, float angleInRadians)\n{\n    float cosAngle = cos(angleInRadians);\n    float sinAngle = sin(angleInRadians);\n\n    // time dependent sampling directions\n    vec2 s0 = vec2(1.0/17.0, 0.0);\n    vec2 s1 = vec2(-1.0/29.0, 0.0);\n    vec2 s2 = vec2(1.0/101.0, 1.0/59.0);\n    vec2 s3 = vec2(-1.0/109.0, -1.0/57.0);\n\n    // rotate sampling direction by specified angle\n    s0 = vec2((cosAngle * s0.x) - (sinAngle * s0.y), (sinAngle * s0.x) + (cosAngle * s0.y));\n    s1 = vec2((cosAngle * s1.x) - (sinAngle * s1.y), (sinAngle * s1.x) + (cosAngle * s1.y));\n    s2 = vec2((cosAngle * s2.x) - (sinAngle * s2.y), (sinAngle * s2.x) + (cosAngle * s2.y));\n    s3 = vec2((cosAngle * s3.x) - (sinAngle * s3.y), (sinAngle * s3.x) + (cosAngle * s3.y));\n\n    vec2 uv0 = (uv/103.0) + (time * s0);\n    vec2 uv1 = uv/107.0 + (time * s1) + vec2(0.23);\n    vec2 uv2 = uv/vec2(897.0, 983.0) + (time * s2) + vec2(0.51);\n    vec2 uv3 = uv/vec2(991.0, 877.0) + (time * s3) + vec2(0.71);\n\n    uv0 = fract(uv0);\n    uv1 = fract(uv1);\n    uv2 = fract(uv2);\n    uv3 = fract(uv3);\n    vec4 noise = (texture2D(normalMap, uv0)) +\n                 (texture2D(normalMap, uv1)) +\n                 (texture2D(normalMap, uv2)) +\n                 (texture2D(normalMap, uv3));\n\n    // average and scale to between -1 and 1\n    return ((noise / 4.0) - 0.5) * 2.0;\n}\n",

    "czm_getWgs84EllipsoidEC": "\n/**\n * Returns the WGS84 ellipsoid, with its center at the origin of world coordinates, in eye coordinates.\n *\n * @name czm_getWgs84EllipsoidEC\n * @glslFunction\n *\n * @returns {czm_ellipsoid} The WGS84 ellipsoid, with its center at the origin of world coordinates, in eye coordinates.\n *\n * @see Ellipsoid.WGS84\n *\n * @example\n * czm_ellipsoid ellipsoid = czm_getWgs84EllipsoidEC();\n */\nczm_ellipsoid czm_getWgs84EllipsoidEC()\n{\n    vec3 radii = vec3(6378137.0, 6378137.0, 6356752.314245);\n    vec3 inverseRadii = vec3(1.0 / radii.x, 1.0 / radii.y, 1.0 / radii.z);\n    vec3 inverseRadiiSquared = inverseRadii * inverseRadii;\n    czm_ellipsoid temp = czm_ellipsoid(czm_f_view[3].xyz, radii, inverseRadii, inverseRadiiSquared);\n    return temp;\n}\n",

    "czm_hue": "\n/**\n * Adjusts the hue of a color.\n * \n * @name czm_hue\n * @glslFunction\n * \n * @param {vec3} rgb The color.\n * @param {float} adjustment The amount to adjust the hue of the color in radians.\n *\n * @returns {float} The color with the hue adjusted.\n *\n * @example\n * vec3 adjustHue = czm_hue(color, czm_pi); // The same as czm_hue(color, -czm_pi)\n */\nvec3 czm_hue(vec3 rgb, float adjustment)\n{\n    const mat3 toYIQ = mat3(0.299,     0.587,     0.114,\n                            0.595716, -0.274453, -0.321263,\n                            0.211456, -0.522591,  0.311135);\n    const mat3 toRGB = mat3(1.0,  0.9563,  0.6210,\n                            1.0, -0.2721, -0.6474,\n                            1.0, -1.107,   1.7046);\n    \n    vec3 yiq = toYIQ * rgb;\n    float hue = atan(yiq.z, yiq.y) + adjustment;\n    float chroma = sqrt(yiq.z * yiq.z + yiq.y * yiq.y);\n    \n    vec3 color = vec3(yiq.x, chroma * cos(hue), chroma * sin(hue));\n    return toRGB * color;\n}\n",

    "czm_isEmpty": "\n/**\n * Determines if a time interval is empty.\n *\n * @name czm_isEmpty\n * @glslFunction \n * \n * @param {czm_raySegment} interval The interval to test.\n * \n * @returns {bool} <code>true</code> if the time interval is empty; otherwise, <code>false</code>.\n *\n * @example\n * bool b0 = czm_isEmpty(czm_emptyRaySegment);      // true\n * bool b1 = czm_isEmpty(czm_raySegment(0.0, 1.0)); // false\n * bool b2 = czm_isEmpty(czm_raySegment(1.0, 1.0)); // false, contains 1.0.\n */\nbool czm_isEmpty(czm_raySegment interval)\n{\n    return (interval.stop < 0.0);\n}\n",

    "czm_isFull": "\n/**\n * Determines if a time interval is empty.\n *\n * @name czm_isFull\n * @glslFunction \n * \n * @param {czm_raySegment} interval The interval to test.\n * \n * @returns {bool} <code>true</code> if the time interval is empty; otherwise, <code>false</code>.\n *\n * @example\n * bool b0 = czm_isEmpty(czm_emptyRaySegment);      // true\n * bool b1 = czm_isEmpty(czm_raySegment(0.0, 1.0)); // false\n * bool b2 = czm_isEmpty(czm_raySegment(1.0, 1.0)); // false, contains 1.0.\n */\nbool czm_isFull(czm_raySegment interval)\n{\n    return (interval.start == 0.0 && interval.stop == czm_infinity);\n}\n",

    "czm_latitudeToWebMercatorFraction": "\n/**\n * Computes the fraction of a Web Wercator rectangle at which a given geodetic latitude is located.\n *\n * @name czm_latitudeToWebMercatorFraction\n * @glslFunction\n *\n * @param {float} latitude The geodetic latitude, in radians.\n * @param {float} southMercatorY The Web Mercator coordinate of the southern boundary of the rectangle.\n * @param {float} oneOverMercatorHeight The total height of the rectangle in Web Mercator coordinates.\n *\n * @returns {float} The fraction of the rectangle at which the latitude occurs.  If the latitude is the southern\n *          boundary of the rectangle, the return value will be zero.  If it is the northern boundary, the return\n *          value will be 1.0.  Latitudes in between are mapped according to the Web Mercator projection.\n */ \nfloat czm_latitudeToWebMercatorFraction(float latitude, float southMercatorY, float oneOverMercatorHeight)\n{\n    float sinLatitude = sin(latitude);\n    float mercatorY = 0.5 * log((1.0 + sinLatitude) / (1.0 - sinLatitude));\n    \n    return (mercatorY - southMercatorY) * oneOverMercatorHeight;\n}\n",

    "czm_luminance": "\n/**\n * Computes the luminance of a color. \n *\n * @name czm_luminance\n * @glslFunction\n *\n * @param {vec3} rgb The color.\n * \n * @returns {float} The luminance.\n *\n * @example\n * float light = czm_luminance(vec3(0.0)); // 0.0\n * float dark = czm_luminance(vec3(1.0));  // ~1.0 \n */\nfloat czm_luminance(vec3 rgb)\n{\n    // Algorithm from Chapter 10 of Graphics Shaders.\n    const vec3 W = vec3(0.2125, 0.7154, 0.0721);\n    return dot(rgb, W);\n}\n",

    "czm_metersPerPixel": "\n/**\n * Computes the size of a pixel in meters at a distance from the eye.\n \n * @name czm_metersPerPixel\n * @glslFunction\n *\n * @param {vec3} positionEC The position to get the meters per pixel in eye coordinates.\n *\n * @returns {float} The meters per pixel at positionEC.\n */\nfloat czm_metersPerPixel(vec4 positionEC)\n{\n    float width = czm_f_viewport.z;\n    float height = czm_f_viewport.w;\n    float pixelWidth;\n    float pixelHeight;\n    \n    float top = czm_frustumPlanes.x;\n    float bottom = czm_frustumPlanes.y;\n    float left = czm_frustumPlanes.z;\n    float right = czm_frustumPlanes.w;\n    \n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        float frustumWidth = right - left;\n        float frustumHeight = top - bottom;\n        pixelWidth = frustumWidth / width;\n        pixelHeight = frustumHeight / height;\n    }\n    else\n    {\n        float distanceToPixel = -positionEC.z;\n        float inverseNear = 1.0 / czm_currentFrustum.x;\n        float tanTheta = top * inverseNear;\n        pixelHeight = 2.0 * distanceToPixel * tanTheta / height;\n        tanTheta = right * inverseNear;\n        pixelWidth = 2.0 * distanceToPixel * tanTheta / width;\n    }\n\n    return max(pixelWidth, pixelHeight);\n}\n",

    "czm_modelToWindowCoordinates": "\n/**\n * Transforms a position from model to window coordinates.  The transformation\n * from model to clip coordinates is done using {@link czm_f_modelViewProjection}.\n * The transform from normalized device coordinates to window coordinates is\n * done using {@link czm_f_viewportTransformation}, which assumes a depth range\n * of <code>near = 0</code> and <code>far = 1</code>.\n * <br /><br />\n * This transform is useful when there is a need to manipulate window coordinates\n * in a vertex shader as done by {@link BillboardCollection}.\n * <br /><br />\n * This function should not be confused with {@link czm_f_viewportOrthographic},\n * which is an orthographic projection matrix that transforms from window \n * coordinates to clip coordinates.\n *\n * @name czm_modelToWindowCoordinates\n * @glslFunction\n *\n * @param {vec4} position The position in model coordinates to transform.\n *\n * @returns {vec4} The transformed position in window coordinates.\n *\n * @see czm_eyeToWindowCoordinates\n * @see czm_f_modelViewProjection\n * @see czm_f_viewportTransformation\n * @see czm_f_viewportOrthographic\n * @see BillboardCollection\n *\n * @example\n * vec4 positionWC = czm_modelToWindowCoordinates(positionMC);\n */\nvec4 czm_modelToWindowCoordinates(vec4 position)\n{\n    vec4 q = czm_f_modelViewProjection * position;                // clip coordinates\n    q.xyz /= q.w;                                                // normalized device coordinates\n    q.xyz = (czm_f_viewportTransformation * vec4(q.xyz, 1.0)).xyz; // window coordinates\n    return q;\n}\n",

    "czm_multiplyWithColorBalance": "\n/**\n * DOC_TBA\n *\n * @name czm_multiplyWithColorBalance\n * @glslFunction\n */\nvec3 czm_multiplyWithColorBalance(vec3 left, vec3 right)\n{\n    // Algorithm from Chapter 10 of Graphics Shaders.\n    const vec3 W = vec3(0.2125, 0.7154, 0.0721);\n    \n    vec3 target = left * right;\n    float leftLuminance = dot(left, W);\n    float rightLuminance = dot(right, W);\n    float targetLuminance = dot(target, W);\n    \n    return ((leftLuminance + rightLuminance) / (2.0 * targetLuminance)) * target;\n}\n",

    "czm_nearFarScalar": "\n/**\n * Computes a value that scales with distance.  The scaling is clamped at the near and\n * far distances, and does not extrapolate.  This function works with the\n * {@link NearFarScalar} JavaScript class.\n *\n * @name czm_nearFarScalar\n * @glslFunction\n *\n * @param {vec4} nearFarScalar A vector with 4 components: Near distance (x), Near value (y), Far distance (z), Far value (w).\n * @param {float} cameraDistSq The square of the current distance from the camera.\n *\n * @returns {float} The value at this distance.\n */\nfloat czm_nearFarScalar(vec4 nearFarScalar, float cameraDistSq)\n{\n    float valueAtMin = nearFarScalar.y;\n    float valueAtMax = nearFarScalar.w;\n    float nearDistanceSq = nearFarScalar.x * nearFarScalar.x;\n    float farDistanceSq = nearFarScalar.z * nearFarScalar.z;\n\n    float t = (cameraDistSq - nearDistanceSq) / (farDistanceSq - nearDistanceSq);\n\n    t = pow(clamp(t, 0.0, 1.0), 0.2);\n\n    return mix(valueAtMin, valueAtMax, t);\n}\n",

    "czm_octDecode": "\n/**\n * Decodes a unit-length vector in 'oct' encoding to a normalized 3-component Cartesian vector.\n * The 'oct' encoding is described in 'A Survey of Efficient Representations of Independent Unit Vectors',\n * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n * \n * @name czm_octDecode\n * @param {vec2} encoded The oct-encoded, unit-length vector\n * @returns {vec3} The decoded and normalized vector\n */\n vec3 czm_octDecode(vec2 encoded)\n {\n    encoded = encoded / 255.0 * 2.0 - 1.0;\n    vec3 v = vec3(encoded.x, encoded.y, 1.0 - abs(encoded.x) - abs(encoded.y));\n    if (v.z < 0.0)\n    {\n        v.xy = (1.0 - abs(v.yx)) * czm_signNotZero(v.xy);\n    }\n    \n    return normalize(v);\n }\n\n /**\n * Decodes a unit-length vector in 'oct' encoding packed into a floating-point number to a normalized 3-component Cartesian vector.\n * The 'oct' encoding is described in 'A Survey of Efficient Representations of Independent Unit Vectors',\n * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n * \n * @name czm_octDecode\n * @param {float} encoded The oct-encoded, unit-length vector\n * @returns {vec3} The decoded and normalized vector\n */\n vec3 czm_octDecode(float encoded)\n {\n    float temp = encoded / 256.0;\n    float x = floor(temp);\n    float y = (temp - x) * 256.0;\n    return czm_octDecode(vec2(x, y));\n }\n \n/**\n * Decodes three unit-length vectors in 'oct' encoding packed into two floating-point numbers to normalized 3-component Cartesian vectors.\n * The 'oct' encoding is described in 'A Survey of Efficient Representations of Independent Unit Vectors',\n * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n * \n * @name czm_octDecode\n * @param {vec2} encoded The packed oct-encoded, unit-length vectors.\n * @param {vec3} vector1 One decoded and normalized vector.\n * @param {vec3} vector2 One decoded and normalized vector.\n * @param {vec3} vector3 One decoded and normalized vector.\n */\n  void czm_octDecode(vec2 encoded, out vec3 vector1, out vec3 vector2, out vec3 vector3)\n {\n    float temp = encoded.x / 65536.0;\n    float x = floor(temp);\n    float encodedFloat1 = (temp - x) * 65536.0;\n\n    temp = encoded.y / 65536.0;\n    float y = floor(temp);\n    float encodedFloat2 = (temp - y) * 65536.0;\n\n    vector1 = czm_octDecode(encodedFloat1);\n    vector2 = czm_octDecode(encodedFloat2);\n    vector3 = czm_octDecode(vec2(x, y));\n }\n ",

    "czm_packDepth": "\n/**\n * Packs a depth value into a vec3 that can be represented by unsigned bytes.\n *\n * @name czm_packDepth\n * @glslFunction\n *\n * @param {float} depth The floating-point depth.\n * @returns {vec3} The packed depth.\n */\nvec4 czm_packDepth(float depth)\n{\n    // See Aras Pranckevičius' post Encoding Floats to RGBA\n    // http://aras-p.info/blog/2009/07/30/encoding-floats-to-rgba-the-final/\n    vec4 enc = vec4(1.0, 255.0, 65025.0, 160581375.0) * depth;\n    enc = fract(enc);\n    enc -= enc.yzww * vec4(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0, 0.0);\n    return enc;\n}\n",

    "czm_phong": "\nfloat czm_private_getLambertDiffuseOfMaterial(vec3 lightDirectionEC, czm_material material)\n{\n    return czm_getLambertDiffuse(lightDirectionEC, material.normal);\n}\n\nfloat czm_private_getSpecularOfMaterial(vec3 lightDirectionEC, vec3 toEyeEC, czm_material material)\n{\n    return czm_getSpecular(lightDirectionEC, toEyeEC, material.normal, material.shininess);\n}\n\n/**\n * Computes a color using the Phong lighting model.\n *\n * @name czm_phong\n * @glslFunction\n *\n * @param {vec3} toEye A normalized vector from the fragment to the eye in eye coordinates.\n * @param {czm_material} material The fragment's material.\n * \n * @returns {vec4} The computed color.\n * \n * @example\n * vec3 positionToEyeEC = // ...\n * czm_material material = // ...\n * gl_FragColor = czm_phong(normalize(positionToEyeEC), material);\n *\n * @see czm_getMaterial\n */\nvec4 czm_phong(vec3 toEye, czm_material material)\n{\n    // Diffuse from directional light sources at eye (for top-down)\n    float diffuse = czm_private_getLambertDiffuseOfMaterial(vec3(0.0, 0.0, 1.0), material);\n    if (czm_sceneMode == czm_sceneMode3D) {\n        // (and horizon views in 3D)\n        diffuse += czm_private_getLambertDiffuseOfMaterial(vec3(0.0, 1.0, 0.0), material);\n    }\n\n    // Specular from sun and pseudo-moon\n    float specular = czm_private_getSpecularOfMaterial(czm_a_sunDirectionEC, toEye, material) + czm_private_getSpecularOfMaterial(czm_a_moonDirectionEC, toEye, material);\n\n    // Temporary workaround for adding ambient.\n    vec3 materialDiffuse = material.diffuse * 0.5;\n    \n    vec3 ambient = materialDiffuse;\n    vec3 color = ambient + material.emission;\n    color += materialDiffuse * diffuse;\n    color += material.specular * specular;\n\n    return vec4(color, material.alpha);\n}\n\nvec4 czm_private_phong(vec3 toEye, czm_material material)\n{\n    float diffuse = czm_private_getLambertDiffuseOfMaterial(czm_a_sunDirectionEC, material);\n    float specular = czm_private_getSpecularOfMaterial(czm_a_sunDirectionEC, toEye, material);\n\n    vec3 ambient = vec3(0.0);\n    vec3 color = ambient + material.emission;\n    color += material.diffuse * diffuse;\n    color += material.specular * specular;\n\n    return vec4(color, material.alpha);\n}",

    "czm_pointAlongRay": "\n/**\n * Computes the point along a ray at the given time.  <code>time</code> can be positive, negative, or zero.\n *\n * @name czm_pointAlongRay\n * @glslFunction\n *\n * @param {czm_ray} ray The ray to compute the point along.\n * @param {float} time The time along the ray.\n * \n * @returns {vec3} The point along the ray at the given time.\n * \n * @example\n * czm_ray ray = czm_ray(vec3(0.0), vec3(1.0, 0.0, 0.0)); // origin, direction\n * vec3 v = czm_pointAlongRay(ray, 2.0); // (2.0, 0.0, 0.0)\n */\nvec3 czm_pointAlongRay(czm_ray ray, float time)\n{\n    return ray.origin + (time * ray.direction);\n}\n",

    "czm_rayEllipsoidIntersectionInterval": "\n/**\n * DOC_TBA\n *\n * @name czm_rayEllipsoidIntersectionInterval\n * @glslFunction\n */\nczm_raySegment czm_rayEllipsoidIntersectionInterval(czm_ray ray, czm_ellipsoid ellipsoid)\n{\n   // ray and ellipsoid center in eye coordinates.  radii in model coordinates.\n    vec3 q = ellipsoid.inverseRadii * (czm_f_inverseModelView * vec4(ray.origin, 1.0)).xyz;\n    vec3 w = ellipsoid.inverseRadii * (czm_f_inverseModelView * vec4(ray.direction, 0.0)).xyz;\n   \n    q = q - ellipsoid.inverseRadii * (czm_f_inverseModelView * vec4(ellipsoid.center, 1.0)).xyz;\n    \n    float q2 = dot(q, q);\n    float qw = dot(q, w);\n    \n    if (q2 > 1.0) // Outside ellipsoid.\n    {\n        if (qw >= 0.0) // Looking outward or tangent (0 intersections).\n        {\n            return czm_emptyRaySegment;\n        }\n        else // qw < 0.0.\n        {\n            float qw2 = qw * qw;\n            float difference = q2 - 1.0; // Positively valued.\n            float w2 = dot(w, w);\n            float product = w2 * difference;\n            \n            if (qw2 < product) // Imaginary roots (0 intersections).\n            {\n                return czm_emptyRaySegment;     \n            }   \n            else if (qw2 > product) // Distinct roots (2 intersections).\n            {\n                float discriminant = qw * qw - product;\n                float temp = -qw + sqrt(discriminant); // Avoid cancellation.\n                float root0 = temp / w2;\n                float root1 = difference / temp;\n                if (root0 < root1)\n                {\n                    czm_raySegment i = czm_raySegment(root0, root1);\n                    return i;\n                }\n                else\n                {\n                    czm_raySegment i = czm_raySegment(root1, root0);\n                    return i;\n                }\n            }\n            else // qw2 == product.  Repeated roots (2 intersections).\n            {\n                float root = sqrt(difference / w2);\n                czm_raySegment i = czm_raySegment(root, root);\n                return i;\n            }\n        }\n    }\n    else if (q2 < 1.0) // Inside ellipsoid (2 intersections).\n    {\n        float difference = q2 - 1.0; // Negatively valued.\n        float w2 = dot(w, w);\n        float product = w2 * difference; // Negatively valued.\n        float discriminant = qw * qw - product;\n        float temp = -qw + sqrt(discriminant); // Positively valued.\n        czm_raySegment i = czm_raySegment(0.0, temp / w2);\n        return i;\n    }\n    else // q2 == 1.0. On ellipsoid.\n    {\n        if (qw < 0.0) // Looking inward.\n        {\n            float w2 = dot(w, w);\n            czm_raySegment i = czm_raySegment(0.0, -qw / w2);\n            return i;\n        }\n        else // qw >= 0.0.  Looking outward or tangent.\n        {\n            return czm_emptyRaySegment;\n        }\n    }\n}\n",

    "czm_RGBToXYZ": "\n/**\n * Converts an RGB color to CIE Yxy.\n * <p>The conversion is described in\n * {@link http://content.gpwiki.org/index.php/D3DBook:High-Dynamic_Range_Rendering#Luminance_Transform|Luminance Transform}\n * </p>\n * \n * @name czm_RGBToXYZ\n * @glslFunction\n * \n * @param {vec3} rgb The color in RGB.\n *\n * @returns {vec3} The color in CIE Yxy.\n *\n * @example\n * vec3 xyz = czm_RGBToXYZ(rgb);\n * xyz.x = max(xyz.x - luminanceThreshold, 0.0);\n * rgb = czm_XYZToRGB(xyz);\n */\nvec3 czm_RGBToXYZ(vec3 rgb)\n{\n    const mat3 RGB2XYZ = mat3(0.4124, 0.2126, 0.0193,\n                              0.3576, 0.7152, 0.1192,\n                              0.1805, 0.0722, 0.9505);\n    vec3 xyz = RGB2XYZ * rgb;\n    vec3 Yxy;\n    Yxy.r = xyz.g;\n    float temp = dot(vec3(1.0), xyz);\n    Yxy.gb = xyz.rg / temp;\n    return Yxy;\n}\n",

    "czm_saturation": "\n/**\n * Adjusts the saturation of a color.\n * \n * @name czm_saturation\n * @glslFunction\n * \n * @param {vec3} rgb The color.\n * @param {float} adjustment The amount to adjust the saturation of the color.\n *\n * @returns {float} The color with the saturation adjusted.\n *\n * @example\n * vec3 greyScale = czm_saturation(color, 0.0);\n * vec3 doubleSaturation = czm_saturation(color, 2.0);\n */\nvec3 czm_saturation(vec3 rgb, float adjustment)\n{\n    // Algorithm from Chapter 16 of OpenGL Shading Language\n    const vec3 W = vec3(0.2125, 0.7154, 0.0721);\n    vec3 intensity = vec3(dot(rgb, W));\n    return mix(intensity, rgb, adjustment);\n}\n",

    "czm_signNotZero": "\n/**\n * Returns 1.0 if the given value is positive or zero, and -1.0 if it is negative.  This is similar to the GLSL\n * built-in function <code>sign</code> except that returns 1.0 instead of 0.0 when the input value is 0.0.\n * \n * @name czm_signNotZero\n * @glslFunction\n *\n * @param {} value The value for which to determine the sign.\n * @returns {} 1.0 if the value is positive or zero, -1.0 if the value is negative.\n */\nfloat czm_signNotZero(float value)\n{\n    return value >= 0.0 ? 1.0 : -1.0;\n}\n\nvec2 czm_signNotZero(vec2 value)\n{\n    return vec2(czm_signNotZero(value.x), czm_signNotZero(value.y));\n}\n\nvec3 czm_signNotZero(vec3 value)\n{\n    return vec3(czm_signNotZero(value.x), czm_signNotZero(value.y), czm_signNotZero(value.z));\n}\n\nvec4 czm_signNotZero(vec4 value)\n{\n    return vec4(czm_signNotZero(value.x), czm_signNotZero(value.y), czm_signNotZero(value.z), czm_signNotZero(value.w));\n}",

    "czm_tangentToEyeSpaceMatrix": "\n/**\n * Creates a matrix that transforms vectors from tangent space to eye space.\n *\n * @name czm_tangentToEyeSpaceMatrix\n * @glslFunction\n * \n * @param {vec3} normalEC The normal vector in eye coordinates.\n * @param {vec3} tangentEC The tangent vector in eye coordinates.\n * @param {vec3} binormalEC The binormal vector in eye coordinates.\n *\n * @returns {mat3} The matrix that transforms from tangent space to eye space.\n *\n * @example\n * mat3 tangentToEye = czm_tangentToEyeSpaceMatrix(normalEC, tangentEC, binormalEC);\n * vec3 normal = tangentToEye * texture2D(normalMap, st).xyz;\n */\nmat3 czm_tangentToEyeSpaceMatrix(vec3 normalEC, vec3 tangentEC, vec3 binormalEC)\n{\n    vec3 normal = normalize(normalEC);\n    vec3 tangent = normalize(tangentEC);\n    vec3 binormal = normalize(binormalEC);\n    return mat3(tangent.x,  tangent.y,  tangent.z,\n                binormal.x, binormal.y, binormal.z,\n                normal.x,   normal.y,   normal.z);\n}\n",

    "czm_translateRelativeToEye": "\n/**\n * Translates a position (or any <code>vec3</code>) that was encoded with {@link EncodedCartesian3},\n * and then provided to the shader as separate <code>high</code> and <code>low</code> bits to\n * be relative to the eye.  As shown in the example, the position can then be transformed in eye\n * or clip coordinates using {@link czm_modelViewRelativeToEye} or {@link czm_modelViewProjectionRelativeToEye},\n * respectively.\n * <p>\n * This technique, called GPU RTE, eliminates jittering artifacts when using large coordinates as\n * described in {@link http://blogs.agi.com/insight3d/index.php/2008/09/03/precisions-precisions/|Precisions, Precisions}.\n * </p>\n *\n * @name czm_translateRelativeToEye\n * @glslFunction\n *\n * @param {vec3} high The position's high bits.\n * @param {vec3} low The position's low bits.\n * @returns {vec3} The position translated to be relative to the camera's position.\n *\n * @example\n * attribute vec3 positionHigh;\n * attribute vec3 positionLow;\n * \n * void main() \n * {\n *   vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n *   gl_Position = czm_modelViewProjectionRelativeToEye * p;\n * }\n *\n * @see czm_modelViewRelativeToEye\n * @see czm_modelViewProjectionRelativeToEye\n * @see czm_computePosition\n * @see EncodedCartesian3\n */\nvec4 czm_translateRelativeToEye(vec3 high, vec3 low)\n{\n    vec3 highDifference = high - czm_encodedCameraPositionMCHigh;\n    vec3 lowDifference = low - czm_encodedCameraPositionMCLow;\n\n    return vec4(highDifference + lowDifference, 1.0);\n}\n",

    "czm_translucentPhong": "\n/**\n * @private\n */\nvec4 czm_translucentPhong(vec3 toEye, czm_material material)\n{\n    // Diffuse from directional light sources at eye (for top-down and horizon views)\n    float diffuse = czm_getLambertDiffuse(vec3(0.0, 0.0, 1.0), material.normal);\n    \n    if (czm_sceneMode == czm_sceneMode3D) {\n        // (and horizon views in 3D)\n        diffuse += czm_getLambertDiffuse(vec3(0.0, 1.0, 0.0), material.normal);\n    }\n    \n    diffuse = clamp(diffuse, 0.0, 1.0);\n\n    // Specular from sun and pseudo-moon\n    float specular = czm_getSpecular(czm_a_sunDirectionEC, toEye, material.normal, material.shininess);\n    specular += czm_getSpecular(czm_a_moonDirectionEC, toEye, material.normal, material.shininess);\n\n    // Temporary workaround for adding ambient.\n    vec3 materialDiffuse = material.diffuse * 0.5;\n\n    vec3 ambient = materialDiffuse;\n    vec3 color = ambient + material.emission;\n    color += materialDiffuse * diffuse;\n    color += material.specular * specular;\n\n    return vec4(color, material.alpha);\n}",

    "czm_transpose": "\n/**\n * Returns the transpose of the matrix.  The input <code>matrix</code> can be \n * a <code>mat2</code>, <code>mat3</code>, or <code>mat4</code>.\n *\n * @name czm_transpose\n * @glslFunction\n *\n * @param {} matrix The matrix to transpose.\n *\n * @returns {} The transposed matrix.\n *\n * @example\n * // GLSL declarations\n * mat2 czm_transpose(mat2 matrix);\n * mat3 czm_transpose(mat3 matrix);\n * mat4 czm_transpose(mat4 matrix);\n *\n * // Tranpose a 3x3 rotation matrix to find its inverse.\n * mat3 eastNorthUpToEye = czm_eastNorthUpToEyeCoordinates(\n *     positionMC, normalEC);\n * mat3 eyeToEastNorthUp = czm_transpose(eastNorthUpToEye);\n */\nmat2 czm_transpose(mat2 matrix)\n{\n    return mat2(\n        matrix[0][0], matrix[1][0],\n        matrix[0][1], matrix[1][1]);\n}\n\nmat3 czm_transpose(mat3 matrix)\n{\n    return mat3(\n        matrix[0][0], matrix[1][0], matrix[2][0],\n        matrix[0][1], matrix[1][1], matrix[2][1],\n        matrix[0][2], matrix[1][2], matrix[2][2]);\n}\n\nmat4 czm_transpose(mat4 matrix)\n{\n    return mat4(\n        matrix[0][0], matrix[1][0], matrix[2][0], matrix[3][0],\n        matrix[0][1], matrix[1][1], matrix[2][1], matrix[3][1],\n        matrix[0][2], matrix[1][2], matrix[2][2], matrix[3][2],\n        matrix[0][3], matrix[1][3], matrix[2][3], matrix[3][3]);\n}\n",

    "czm_unpackDepth": "\n/**\n * Unpacks a vec3 depth depth value to a float.\n *\n * @name czm_unpackDepth\n * @glslFunction\n *\n * @param {vec3} packedDepth The packed depth.\n *\n * @returns {float} The floating-point depth.\n */\n float czm_unpackDepth(vec4 packedDepth)\n {\n    // See Aras Pranckevičius' post Encoding Floats to RGBA\n    // http://aras-p.info/blog/2009/07/30/encoding-floats-to-rgba-the-final/\n    return dot(packedDepth, vec4(1.0, 1.0 / 255.0, 1.0 / 65025.0, 1.0 / 160581375.0));\n }\n",

    "czm_windowToEyeCoordinates": "\n/**\n * Transforms a position from window to eye coordinates.\n * The transform from window to normalized device coordinates is done using components\n * of (@link czm_f_viewport} and {@link czm_f_viewportTransformation} instead of calculating\n * the inverse of <code>czm_f_viewportTransformation</code>. The transformation from \n * normalized device coordinates to clip coordinates is done using <code>positionWC.w</code>,\n * which is expected to be the scalar used in the perspective divide. The transformation\n * from clip to eye coordinates is done using {@link czm_f_inverseProjection}.\n *\n * @name czm_windowToEyeCoordinates\n * @glslFunction\n *\n * @param {vec4} fragmentCoordinate The position in window coordinates to transform.\n *\n * @returns {vec4} The transformed position in eye coordinates.\n *\n * @see czm_modelToWindowCoordinates\n * @see czm_eyeToWindowCoordinates\n * @see czm_f_inverseProjection\n * @see czm_f_viewport\n * @see czm_f_viewportTransformation\n *\n * @example\n * vec4 positionEC = czm_windowToEyeCoordinates(gl_FragCoord);\n */\nvec4 czm_windowToEyeCoordinates(vec4 fragmentCoordinate)\n{\n    float x = 2.0 * (fragmentCoordinate.x - czm_f_viewport.x) / czm_f_viewport.z - 1.0;\n    float y = 2.0 * (fragmentCoordinate.y - czm_f_viewport.y) / czm_f_viewport.w - 1.0;\n    float z = (fragmentCoordinate.z - czm_f_viewportTransformation[3][2]) / czm_f_viewportTransformation[2][2];\n    vec4 q = vec4(x, y, z, 1.0);\n    q /= fragmentCoordinate.w;\n    q = czm_f_inverseProjection * q;\n    return q;\n}\n",

    "czm_XYZToRGB": "\n/**\n * Converts a CIE Yxy color to RGB.\n * <p>The conversion is described in\n * {@link http://content.gpwiki.org/index.php/D3DBook:High-Dynamic_Range_Rendering#Luminance_Transform|Luminance Transform}\n * </p>\n * \n * @name czm_XYZToRGB\n * @glslFunction\n * \n * @param {vec3} Yxy The color in CIE Yxy.\n *\n * @returns {vec3} The color in RGB.\n *\n * @example\n * vec3 xyz = czm_RGBToXYZ(rgb);\n * xyz.x = max(xyz.x - luminanceThreshold, 0.0);\n * rgb = czm_XYZToRGB(xyz);\n */\nvec3 czm_XYZToRGB(vec3 Yxy)\n{\n    const mat3 XYZ2RGB = mat3( 3.2405, -0.9693,  0.0556,\n                              -1.5371,  1.8760, -0.2040,\n                              -0.4985,  0.0416,  1.0572);\n    vec3 xyz;\n    xyz.r = Yxy.r * Yxy.g / Yxy.b;\n    xyz.g = Yxy.r;\n    xyz.b = Yxy.r * (1.0 - Yxy.g - Yxy.b) / Yxy.b;\n    \n    return XYZ2RGB * xyz;\n}\n",

    "czm_depthRangeStruct": "\n/**\n * @name czm_depthRangeStruct\n * @glslStruct\n */\nstruct czm_depthRangeStruct\n{\n    float near;\n    float far;\n};",

    "czm_ellipsoid": "\n/** DOC_TBA\n *\n * @name czm_ellipsoid\n * @glslStruct\n */\nstruct czm_ellipsoid\n{\n    vec3 center;\n    vec3 radii;\n    vec3 inverseRadii;\n    vec3 inverseRadiiSquared;\n};",

    "czm_material": "\n/**\n * Holds material information that can be used for lighting. Returned by all czm_getMaterial functions.\n *\n * @name czm_material\n * @glslStruct\n *\n * @property {vec3} diffuse Incoming light that scatters evenly in all directions.\n * @property {float} specular Intensity of incoming light reflecting in a single direction.\n * @property {float} shininess The sharpness of the specular reflection.  Higher values create a smaller, more focused specular highlight.\n * @property {vec3} normal Surface's normal in eye coordinates. It is used for effects such as normal mapping. The default is the surface's unmodified normal.\n * @property {vec3} emission Light emitted by the material equally in all directions. The default is vec3(0.0), which emits no light.\n * @property {float} alpha Opacity of this material. 0.0 is completely transparent; 1.0 is completely opaque.\n */\nstruct czm_material\n{\n    vec3 diffuse;\n    float specular;\n    float shininess;\n    vec3 normal;\n    vec3 emission;\n    float alpha;\n};",

    "czm_materialInput": "\n/**\n * Used as input to every material's czm_getMaterial function.\n *\n * @name czm_materialInput\n * @glslStruct\n *\n * @property {float} s 1D texture coordinates.\n * @property {vec2} st 2D texture coordinates.\n * @property {vec3} str 3D texture coordinates.\n * @property {vec3} normalEC Unperturbed surface normal in eye coordinates.\n * @property {mat3} tangentToEyeMatrix Matrix for converting a tangent space normal to eye space.\n * @property {vec3} positionToEyeEC Vector from the fragment to the eye in eye coordinates.  The magnitude is the distance in meters from the fragment to the eye.\n */\nstruct czm_materialInput\n{\n    float s;\n    vec2 st;\n    vec3 str;\n    vec3 normalEC;\n    mat3 tangentToEyeMatrix;\n    vec3 positionToEyeEC;\n};",

    "czm_ray": "\n/**\n * DOC_TBA\n *\n * @name czm_ray\n * @glslStruct\n */\nstruct czm_ray\n{\n    vec3 origin;\n    vec3 direction;\n};",

    "czm_raySegment": "\n/**\n * DOC_TBA\n *\n * @name czm_raySegment\n * @glslStruct\n */\nstruct czm_raySegment\n{\n    float start;\n    float stop;\n};\n\n/**\n * DOC_TBA\n *\n * @name czm_emptyRaySegment\n * @glslConstant \n */\nconst czm_raySegment czm_emptyRaySegment = czm_raySegment(-czm_infinity, -czm_infinity);\n\n/**\n * DOC_TBA\n *\n * @name czm_fullRaySegment\n * @glslConstant \n */\nconst czm_raySegment czm_fullRaySegment = czm_raySegment(0.0, czm_infinity);\n",

]
